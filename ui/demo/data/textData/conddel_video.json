[{"text": "Hi, I'm Vivian Lai from the University of Colorado\u00a0\nBoulder and the title of our paper is Human-AI\u00a0\u00a0", "start_time": 3647, "duration": 6720}, {"text": "Collaboration via Conditional Delegation: A\u00a0\nCase Study of Content Moderation. This is a\u00a0\u00a0", "start_time": 10367, "duration": 6400}, {"text": "joint work with Samuel Carton, Rajat Bhatnagar,\u00a0\nVera Liao, Yunfeng Zhang, and Chenhao Tan.", "start_time": 16767, "duration": 6400}, {"text": "AI has achieved impressive\u00a0\nperformance in many tasks.\u00a0\u00a0", "start_time": 26047, "duration": 3680}, {"text": "For example, Google's AlphaGo beat the strongest\u00a0\nGo player in the world Lee Sedol in 2016.", "start_time": 29727, "duration": 6000}, {"text": "However, it can still fail terribly\u00a0\nbecause they are not always trustworthy.\u00a0\u00a0", "start_time": 37967, "duration": 4160}, {"text": "In the case of autonomous driving, it\u00a0\nhas led to some horrible accidents.", "start_time": 42767, "duration": 4240}, {"text": "In this paper, we ask the following question:\u00a0\u00a0", "start_time": 49567, "duration": 2320}, {"text": "how can imperfect models be used\u00a0\neffectively in collaboration with humans?", "start_time": 52527, "duration": 4800}, {"text": "Prior work has focused on AI\u00a0\nassistance such as explanations\u00a0\u00a0", "start_time": 60207, "duration": 4000}, {"text": "and predictions to determine every decision.", "start_time": 64207, "duration": 2800}, {"text": "However, this is not feasible\u00a0\nand not scalable for some tasks\u00a0\u00a0", "start_time": 70047, "duration": 4080}, {"text": "where a large number of decisions is\u00a0\na key challenge. A good example is\u00a0\u00a0", "start_time": 74127, "duration": 5520}, {"text": "content moderation where moderators decide\u00a0\non individual comments for further actions.", "start_time": 79647, "duration": 5040}, {"text": "In this paper, we use Reddit\u00a0\nas a testbed to assist humans\u00a0\u00a0", "start_time": 87967, "duration": 3360}, {"text": "in making decisions with an imperfect model.", "start_time": 91327, "duration": 2560}, {"text": "Normally Reddit moderators use\u00a0\na tool called AutoModerator with\u00a0\u00a0", "start_time": 97247, "duration": 4640}, {"text": "which they manually customize a rule-based system\u00a0\u00a0", "start_time": 101887, "duration": 3120}, {"text": "to automatically identify comments for\u00a0\ndeleting or reporting for further review.", "start_time": 105007, "duration": 5200}, {"text": "However, this approach misses out on\u00a0\nthe benefit of AI especially since\u00a0\u00a0", "start_time": 112607, "duration": 4560}, {"text": "rigid rules often do not work on informal\u00a0\nlanguages such as social media posts.", "start_time": 117167, "duration": 4800}, {"text": "For example, while there are toxic\u00a0\ncomments that contain curse words\u00a0\u00a0", "start_time": 124367, "duration": 3520}, {"text": "there are also non-toxic comments\u00a0\nthat contain curse words as well.", "start_time": 128527, "duration": 3280}, {"text": "In this work, we propose an alternative\u00a0\nparadigm of human-AI collaboration--conditional\u00a0\u00a0", "start_time": 134607, "duration": 5440}, {"text": "delegation. The goal is to strike\u00a0\na balance between full automation\u00a0\u00a0", "start_time": 140047, "duration": 4720}, {"text": "and manual approaches by allowing\u00a0\nhumans to identify trustworthy regions.", "start_time": 144767, "duration": 4480}, {"text": "At first human and AI work together to identify\u00a0\ntrustworthy regions of AI before deployment.\u00a0\u00a0", "start_time": 151327, "duration": 5840}, {"text": "In other words, model decisions are reliable or\u00a0\ntrustworthy for examples within these regions.", "start_time": 157727, "duration": 6000}, {"text": "Once deployed the AI model only affects\u00a0\ndecisions for instances in the trustworthy\u00a0\u00a0", "start_time": 166127, "duration": 5040}, {"text": "regions. For the remaining decisions, another\u00a0\nset of actions can be taken such as manual review\u00a0\u00a0", "start_time": 171167, "duration": 6400}, {"text": "or employing a different model since the\u00a0\ngiven AI's decision on them cannot be trusted.", "start_time": 177567, "duration": 5040}, {"text": "Conditional delegation employs a greater level of\u00a0\nautomation than human-AI collaboration on every\u00a0\u00a0", "start_time": 185247, "duration": 6080}, {"text": "single decision. It also provides humans with\u00a0\nactive control on when to use an AI model and in\u00a0\u00a0", "start_time": 191327, "duration": 6640}, {"text": "what ways. Now let's take a look at the different\u00a0\ntypes of interfaces we used during the user study.", "start_time": 197967, "duration": 6960}, {"text": "We develop novel interfaces to assist humans\u00a0\nin creating rules. In the manual condition,\u00a0\u00a0", "start_time": 208127, "duration": 5760}, {"text": "there is no AI involved and all comments matching\u00a0\nhuman-created rules will be considered toxic.", "start_time": 213887, "duration": 6240}, {"text": "Conditional delegation is included\u00a0\nin the remaining conditions.", "start_time": 222607, "duration": 3280}, {"text": "What that means is that created rules are\u00a0\nconsidered trustworthy regions of the model\u00a0\u00a0", "start_time": 228207, "duration": 4480}, {"text": "and any comments containing these\u00a0\nwords that are predicted as toxic\u00a0\u00a0", "start_time": 233567, "duration": 4320}, {"text": "will be considered as a toxic comment.", "start_time": 237887, "duration": 5280}, {"text": "In the predicted label condition, users\u00a0\nare shown the comments' predicted labels.\u00a0\u00a0", "start_time": 243167, "duration": 4560}, {"text": "For ease of use, they are also able to\u00a0\nsearch and filter by the predicted labels.", "start_time": 248367, "duration": 4560}, {"text": "In this condition, not only\u00a0\nusers are shown predicted labels,\u00a0\u00a0", "start_time": 255727, "duration": 3920}, {"text": "local explanations which are\u00a0\nwords that the model uses\u00a0\u00a0", "start_time": 259647, "duration": 3360}, {"text": "to determine whether a comment is toxic or\u00a0\nnon-toxic, are shown to the participants.", "start_time": 263007, "duration": 8000}, {"text": "And in the final condition, users are also\u00a0\nshown global explanations which are a list\u00a0\u00a0", "start_time": 271727, "duration": 5280}, {"text": "of words the model uses in determining comment\u00a0\ntoxicity when assessing the entire data set.\u00a0\u00a0", "start_time": 277007, "duration": 5840}, {"text": "Now let's take a look at the measures\u00a0\nthat we use in this experiment.", "start_time": 284767, "duration": 3200}, {"text": "Our main goal is to examine whether humans\u00a0\ncan improve the precision of the model\u00a0\u00a0", "start_time": 291407, "duration": 4720}, {"text": "with good coverage via conditional\u00a0\ndelegation. We use average precision\u00a0\u00a0", "start_time": 296127, "duration": 5840}, {"text": "which reflects the average quality of\u00a0\nevery single rule a person provides.", "start_time": 301967, "duration": 4240}, {"text": "Another measure, rewards, measures the quantity\u00a0\ndifference between reported toxic comments,\u00a0\u00a0", "start_time": 309487, "duration": 5360}, {"text": "also true positives, and\u00a0\nreported non-toxic comments,\u00a0\u00a0", "start_time": 314847, "duration": 3920}, {"text": "also false positives. As such this measure\u00a0\nreflects both precision and coverage.", "start_time": 318767, "duration": 8720}, {"text": "To measure efficiency, we use rules\u00a0\nper minute. Rules per minute is the\u00a0\u00a0", "start_time": 327487, "duration": 4400}, {"text": "number of rules added divided by the\u00a0\ntotal time spent by the participant.", "start_time": 331887, "duration": 4480}, {"text": "Lastly, we use the number of actions to measure\u00a0\nengagement. There are a total of 13 unique actions\u00a0\u00a0", "start_time": 339087, "duration": 6640}, {"text": "and we consider the number of logged actions\u00a0\na participant took during the experiment task.", "start_time": 345727, "duration": 5360}, {"text": "Now let's take a look at the user study results.", "start_time": 353807, "duration": 2320}, {"text": "We find that users are able to create rules with\u00a0\nhigher precision than the model working alone.\u00a0\u00a0", "start_time": 359807, "duration": 5120}, {"text": "As long as predicted labels are provided,\u00a0\npeople can easily identify rules with high\u00a0\u00a0", "start_time": 365647, "duration": 5680}, {"text": "average precision and with high coverage,\u00a0\nas reflected by rewards on this slide.\u00a0\u00a0", "start_time": 371327, "duration": 5520}, {"text": "Recall that rewards measures the\u00a0\nquantity difference between reported\u00a0\u00a0", "start_time": 377727, "duration": 3680}, {"text": "toxic comments and non-toxic comments,\u00a0\nwhich reflects precision and coverage.", "start_time": 381407, "duration": 5120}, {"text": "Through conditional delegation, we show that\u00a0\nelusive complementary performance is achieved,\u00a0\u00a0", "start_time": 389567, "duration": 4960}, {"text": "meaning that human+AI performance exceeds human\u00a0\nalone performance and AI alone performance.", "start_time": 395327, "duration": 6800}, {"text": "When it comes to efficiency, predicted\u00a0\nlabels only lead to the lowest number of\u00a0\u00a0", "start_time": 405647, "duration": 4640}, {"text": "rules per condition. However,\u00a0\nwith the help of explanations,\u00a0\u00a0", "start_time": 410287, "duration": 4720}, {"text": "humans are able to achieve a greater number\u00a0\nof rules per minute. In other words, global\u00a0\u00a0", "start_time": 415007, "duration": 5600}, {"text": "explanations help participants to achieve\u00a0\nthe highest efficiency to create rules.", "start_time": 420607, "duration": 5040}, {"text": "To understand this improvement in\u00a0\nefficiency, we examine the overlap\u00a0\u00a0", "start_time": 428767, "duration": 4160}, {"text": "between human-created rules and the most\u00a0\nfrequent words in global explanations.\u00a0\u00a0", "start_time": 432927, "duration": 4400}, {"text": "Global explanations lead to much higher\u00a0\noverlap than the other conditions.\u00a0\u00a0", "start_time": 438207, "duration": 4000}, {"text": "This observation confirms that global explanations\u00a0\nprovide direct hints for possible rules,\u00a0\u00a0", "start_time": 442927, "duration": 5760}, {"text": "thus improved the efficiency to\u00a0\ncreate the required number of rules.", "start_time": 448687, "duration": 4320}, {"text": "Lastly, we find that users with\u00a0\nall delegation support features\u00a0\u00a0", "start_time": 455807, "duration": 4240}, {"text": "were also much more engaged as\u00a0\ncompared to the manual condition.\u00a0\u00a0", "start_time": 460047, "duration": 3920}, {"text": "In particular, predicted labels only condition\u00a0\nincurred many more actions than other conditions.", "start_time": 465087, "duration": 6080}, {"text": "In summary, we propose conditional delegation\u00a0\nas an alternative paradigm that allows users\u00a0\u00a0", "start_time": 474207, "duration": 5760}, {"text": "to create trustworthy regions\u00a0\nwhen imperfect models are used.\u00a0\u00a0", "start_time": 479967, "duration": 3600}, {"text": "Using content moderation as a testbed,\u00a0\nconditional delegation achieves\u00a0\u00a0", "start_time": 485327, "duration": 4640}, {"text": "complementary performance, improves task\u00a0\nefficiency, and increases engagement.", "start_time": 489967, "duration": 7600}]