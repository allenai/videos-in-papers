,index,page,type,intervals,text,x1,y1,x2,y2,block_type,block_id
0,1,0,Paragraph,"[(0, 1)]",82,0.9468024691358025,0.18559973722222228,0.977147929218107,0.20552501499999998,,
1,2,0,Title,"[(1, 7), (7, 12), (12, 16)]","Comparing the Perceived Legitimacy of Content Moderation Processes: Contractors, Algorithms, Expert Panels, and Digital Juries",0.09429629629629636,0.11617057055555556,0.8313839794238685,0.18314168166666667,,
2,3,0,Author,"[(16, 24), (24, 31), (31, 39), (39, 44), (44, 51), (51, 57)]","CHRISTINA A. PAN ∗ , Stanford University, USA SAHIL YAKHMI ∗ , Stanford University, USA TARA P. IYER ∗ , Stanford University, USA EVAN STRASNICK, Stanford University, USA AMY X. ZHANG, University of Washington, USA MICHAEL S. BERNSTEIN, Stanford University, USA",0.09360082304526754,0.20210668097222217,0.5312413201646091,0.3086287879166667,,
3,4,0,Abstract,"[(57, 71), (71, 87), (87, 102), (102, 115), (115, 129), (129, 145), (145, 162), (162, 175), (175, 188), (188, 201), (201, 215)]","While research continues to investigate and improve the accuracy, fairness, and normative appropriateness of content moderation processes on large social media platforms, even the best process cannot be effective if users reject its authority as illegitimate. We present a survey experiment comparing the perceived institutional legitimacy of four popular content moderation processes. We conducted a within-subjects experiment in which we showed US Facebook users moderation decisions and randomized the description of whether those decisions were made by paid contractors, algorithms, expert panels, or juries of users. Prior work suggests that juries will have the highest perceived legitimacy due to the benefits of judicial independence and democratic representation. However, expert panels had greater perceived legitimacy than algorithms or juries. Moreover, outcome alignment—agreement with the decision—played a larger role than process in determining perceived legitimacy. These results suggest benefits to incorporating expert oversight in content moderation and underscore that any process will face legitimacy challenges derived from disagreement about outcomes.",0.09341152263374486,0.32054240666666667,0.908546887901235,0.48520268444444437,,
4,5,0,Paragraph,"[(215, 228)]",CCS Concepts: • Human-centered computing → Empirical studies in collaborative and social com-,0.09429629629629631,0.4946868511111111,0.9090149432098763,0.5099919977777778,,
5,5,0,Paragraph,"[(228, 230)]",puting .,0.09429629629629631,0.5099062955555556,0.15362882304526748,0.5252114422222223,,
6,6,0,Keywords,"[(230, 242)]",Additional Key Words and Phrases: content moderation; platform governance; legitimacy; social media,0.09365020576131688,0.5332271288888889,0.8684320329218116,0.5456804622222222,,
7,7,0,Paragraph,"[(242, 263), (263, 274), (274, 290), (290, 291)]","ACM Reference Format: Christina A. Pan, Sahil Yakhmi, Tara P. Iyer, Evan Strasnick, Amy X. Zhang, and Michael S. Bernstein. 2022. Comparing the Perceived Legitimacy of Content Moderation Processes: Contractors, Algorithms, Expert Panels, and Digital Juries. Proc. ACM Hum.-Comput. Interact. 6, CSCW1, Article 82 (April 2022), 32 pages. https://doi.org/10.1145/3512929",0.09361316872427984,0.5580164422222222,0.9085455226469139,0.6284999066666667,,
8,8,0,Section,"(291, 293)",1 INTRODUCTION,0.09429629629629631,0.6479134005555556,0.28586110493827166,0.661750345,,
9,9,0,Paragraph,"[(293, 309), (309, 321)]","Efforts to improve platform design are ineffective if users do not trust platforms and their processes. Large social media platforms—like Facebook, YouTube, and Twitter—have become the new “town",0.09429629629629631,0.665458785,0.9088528217201648,0.6958998961111111,,
10,9,0,Paragraph,"[(321, 329)]",∗ These authors contributed equally to this research.,0.09429629629629631,0.70829938,0.439746777366255,0.7209013058333332,,
11,10,0,Author,"[(329, 342), (342, 343)]","Authors’ addresses: Christina A. Pan, cpan@cs.stanford.edu, Stanford University, Stanford, USA; Sahil Yakhmi, sahil@cs. stanford.edu,StanfordUniversity,Stanford,USA;TaraP.Iyer,tiyer@alumni.stanford.edu,StanfordUniversity,Stanford,USA;EvanStrasnick,estrasnick@stanford.com,StanfordUniversity,Stanford,USA;AmyX.Zhang,axz@cs.uw.edu,UniversityofWashington,Seattle,USA;MichaelS.Bernstein,msb@cs.stanford.edu,StanfordUniversity,Stanford,USA.",0.09429629629629631,0.7353372780555555,0.9082306068537036,0.7879165836111112,,
12,11,0,Paragraph,"[(343, 387), (387, 428), (428, 438)]","Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.",0.09372222222222222,0.8023525558333333,0.9082320991975309,0.8687707502777777,,
13,12,0,Footer,"[(438, 452), (452, 453), (453, 467)]","© 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM. 2573-0142/2022/4-ART82 $15.00 https://doi.org/10.1145/3512929 Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.09316460905349795,0.8729220002777778,0.9057001553497942,0.9450888058333333,,
14,13,1,Header,"[(0, 1), (1, 6)]","82:2 Pan, Yakhmi, Iyer, et. al.",0.09429629629629631,0.08305529208333332,0.9057092407407409,0.09412487541666666,,
15,14,1,Paragraph,"[(6, 21), (21, 33), (33, 46), (46, 49)]","squares” for public discourse [88], but the legitimacy of the rules and processes governing these platforms have increasingly been called into question. Social media platforms face widespread criticism for regulating speech in an opaque [116] and unrepresentative [77] manner without meaningful oversight [77].",0.09429629629629631,0.11764211833333336,0.9057121734341563,0.18129295166666662,,
16,14,1,Paragraph,"[(49, 64), (64, 82), (82, 96), (96, 113), (113, 128), (128, 141), (141, 156), (156, 173), (173, 185), (185, 190)]","Since online platforms have become the “new governors” of speech [83], they have been analyzed through the lens of political theory and legitimacy [16, 48, 83, 100, 131, 149, 151]. Moreover, a large body of sociological work points to the practical importance of perceived legitimacy —the acceptance of authority by those subject to it—for the functioning of institutions [21, 51, 69, 104, 139]. Empirical studies show that when institutions are perceived as highly legitimate by the public, this results in greater acceptance of unpopular decisions along with more cooperation and compliance with authorities in the long term. For instance, when the US Supreme Court decided a contentious election in Bush v. Gore, compliance was swift and the standing of the court was not measurably diminished [53]. As institutions that regularly must make contentious decisions, online platforms similarly depend upon perceived legitimacy.",0.09429629629629631,0.18406017388888896,0.9062373317325102,0.34733600722222224,,
17,14,1,Paragraph,"[(190, 203), (203, 218), (218, 230), (230, 244), (244, 260), (260, 273), (273, 285), (285, 300), (300, 313), (313, 326), (326, 336), (336, 351), (351, 364)]","In this paper, we compare the perceived legitimacy of several content moderation processes that are in wide use or are specifically designed to increase legitimacy of moderation decisions. Understanding the impact of different content moderation processes on perceived legitimacy is critical—crafting even a “perfect” moderation process will not help a platform if that process is viewed by the population as illegitimate. In recent years, scholars have applied the lens of legitimacy to online platforms, including surveying the governance mechanisms they use [34, 59], proposing frameworks with which to evaluate platform legitimacy [129], and proposing more legitimate methods of platform governance [2, 36, 44, 78, 135]. However, most prior work lacks robust, empirical methods of evaluating legitimacy, and existing empirical work does not establish a common basis for comparing disparate processes. Stakeholders seeking to design more legitimate content moderation processes, whether platform owners, academics, or policymakers, currently lack data on how specific processes and proposals affect perceived legitimacy and the extent to which process design matters at all when making decisions about highly disagreed-upon content.",0.09353909465020577,0.3501032294444444,0.9088544616543214,0.5631929516666666,,
18,14,1,Paragraph,"[(364, 377), (377, 391), (391, 407), (407, 422), (422, 435), (435, 442)]","We conducted an online, within-subjects survey experiment in which US Facebook users evalu- ated moderation decisions presented as made by one of four processes: paid contractors, algorithms, expert panels, and juries of users. Paid contractors and algorithms are the two common types of content moderation used at scale [56], while expert panels like the Facebook Oversight Board [150] and digital juries [44] are both recent moderation processes gathering substantial support and debate that are designed to enhance legitimacy.",0.09429629629629631,0.5659615627777778,0.9091768142901232,0.6628193405555556,,
19,14,1,Paragraph,"[(442, 454), (454, 468), (468, 482), (482, 494), (494, 507), (507, 522), (522, 535), (535, 549), (549, 553)]","In our within-subjects survey experiment, for each moderation process, participants were given a randomly selected Facebook post along with a randomly assigned decision outcome. For each post, participants were asked to answer questions about their attitudes towards the post and decision outcome, which measure components of perceived institutional legitimacy. At the end, participants were asked to compare and discuss the four processes. From participants’ responses to the individual posts, we constructed a model that estimates the effect on perceived legitimacy of each moderation process, user alignment with the decision, and demographic variables. In addition to the quantitative analysis, we coded the comparative responses to identify and analyze all meaningfully distinguishable attitudes.",0.09429629629629631,0.6655879516666666,0.907955367753086,0.8122596183333334,,
20,14,1,Paragraph,"[(553, 567), (567, 582), (582, 597), (597, 610), (610, 623), (623, 638)]","We find that expert panels have greater perceived legitimacy than both algorithms and digital juries. These results suggest that users value expertise, even when the nature of that expertise is not well understood. Additionally, we find qualitative evidence of a user preference for group decision making over decisions made by individuals and of acceptance of algorithmic decisions being conditional on factors like human oversight, despite being perceived as impartial. However, we also find that the alignment of user preferences with decision outcomes dominates all tested",0.09353909465020577,0.8150268405555555,0.9079617634962961,0.9118860072222222,,
21,15,1,Footer,"[(638, 652)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.09429629629629631,0.9340192225,0.7380540648148148,0.9450888058333333,,
22,16,2,Header,"[(0, 8), (8, 9)]",Comparing The Perceived Legitimacy of Content Moderation Processes 82:3,0.09429629629629631,0.08305529208333332,0.9057049543209879,0.09412487541666666,,
23,17,2,Paragraph,"[(9, 23), (23, 39), (39, 55), (55, 70), (70, 82), (82, 85)]","process factors in determining perceptions of legitimacy. In other words, whether users agree with the decisions of the content moderation process has a greater impact on the legitimacy users attach to that process than the process itself. While these results suggest platforms may struggle to create processes that can be perceived as legitimate by all users when dealing with highly disagreed-upon content, they also suggest incorporating expert oversight and multiple perspectives into moderation processes can help.",0.09429629629629631,0.11764211833333336,0.9057040661432098,0.21450128500000004,,
24,18,2,Section,"(85, 90)",2 BACKGROUND AND RESEARCH QUESTIONS,0.09429629629629631,0.2414675672222223,0.5581311732510289,0.2553045116666668,,
25,19,2,Paragraph,"[(90, 105), (105, 121), (121, 136), (136, 149), (149, 151)]","In this section, we draw from prior work on platform governance, content moderation, and political legitimacy to motivate our study and methods. In contrast to the body of normative and qualitative work on content moderation, this paper contributes an empirical study that allows for user per- ceptions of multiple moderation processes to be compared with common methods of evaluating perceived legitimacy.",0.09353909465020577,0.2590129516666667,0.9091636271934153,0.3392679516666666,,
26,20,2,Section,"(151, 155)",2.1 Content Moderation Processes,0.09429629629629631,0.3662356227777777,0.4254195016460905,0.38007256722222216,,
27,21,2,Paragraph,"[(155, 172), (172, 188), (188, 206), (206, 217), (217, 234), (234, 240)]","Each day, users posts billions of pieces of content on online platforms [56]. This content must be reviewed so that illegal and harmful posts can be removed in a timely manner, while nevertheless respecting the users’ right to self-expression [56, 92]. In this work, we consider the case of post hoc content moderation takedown decisions, excluding processes involved in crafting content policy, to narrow the focus of the study to an intervention that is easily understood by participants and can be undertaken by several processes.",0.09429629629629631,0.3837810072222222,0.907964715377778,0.480638785,,
28,21,2,Paragraph,"[(240, 252), (252, 266), (266, 277), (277, 290), (290, 303), (303, 317), (317, 330), (330, 341), (341, 345)]","Online platforms employ varied methods to carry out this task. Consequently, researchers have sought to identify patterns in these strategies, for example, distinguishing between artisanal , community-reliant , and industrial moderation processes [22, 56]. Artisanal and community-reliant processes have been used by small platforms and niche communities within larger platforms like Reddit [56, 121]. However, the largest platforms heavily rely upon industrial moderation processes—defined as processes that enable platforms to 1) operate at large scale, 2) enforce well-defined rules, and 3) maintain separation between a) policy creation and b) interpretation and enforcement [22]. Industrial moderation processes heavily overlap with commercial content moderation processes [60, 116].",0.09353909465020577,0.48340739611111105,0.907957279473251,0.6300790627777778,,
29,21,2,Paragraph,"[(345, 360), (360, 374), (374, 389), (389, 403), (403, 418), (418, 430), (430, 442), (442, 456)]","In this work, we limit our scope to investigating the legitimacy of industrial moderation pro- cesses because they impact the most people, being employed by the largest platforms (Facebook, Youtube, Twitter, etc.), and are the processes most central to ongoing public debate over content moderation [22]. As a result, we do not investigate community or artisanal moderation. Although community moderation is also employed by some large platforms, it is more closely linked to subcommunity norms rather than platform-wide rules, and generally does not strictly separate policy creation and enforcement. Community moderation, therefore, should be studied in context of specific community norms and not only from the perspective of post hoc decisions.",0.09370164609053498,0.6328462850000001,0.9091771217777779,0.7661239561111111,,
30,21,2,Paragraph,"[(456, 467)]",We select the four following industrial moderation processes for our study.,0.11479629629629617,0.7656810072222222,0.7414151374485595,0.7795179516666666,,
31,22,2,List,"[(467, 481), (481, 493), (493, 506), (506, 518), (518, 530), (530, 545), (545, 554)]","(1) Paid Individual Contractors, who are hired and trained on a company’s moderation policy (2) Automated Systems, commonly powered by databases of known infringing content and machine learning algorithms, trained with the help of human contractors, that detect certain types of banned content (e.g., explicit language, hate speech, and pornographic images) (3) Digital Juries, or ad-hoc deliberative bodies drawn from the user population (4) Expert Panels, composed of experts in content moderation and related fields like law, human and digital rights, media and journalism, and political science",0.1145699588477365,0.7941546183333335,0.9056976547489711,0.9076179516666667,,
32,23,2,Footer,"[(554, 568)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.26194238683127574,0.9340192225,0.9057001553497942,0.9450888058333333,,
33,24,3,Header,"[(0, 1), (1, 6)]","82:4 Pan, Yakhmi, Iyer, et. al.",0.09429629629629631,0.08305529208333332,0.9057092407407409,0.09412487541666666,,
34,25,3,Paragraph,"[(6, 20), (20, 34), (34, 41)]","Paid Individual Contractors (1) and Automated Systems (2) are selected because they are the industrial processes in widespread use by large platforms, and have been extensively described by many authors (e.g., [22, 56, 60, 116]).",0.09429629629629631,0.11764211833333336,0.9062260571851849,0.16468739611111102,,
35,25,3,Paragraph,"[(41, 56), (56, 71), (71, 89), (89, 105), (105, 121), (121, 137), (137, 153), (153, 165), (165, 180), (180, 195), (195, 209), (209, 223), (223, 241), (241, 242)]","Digital Juries (3) and Expert Panels (4) are selected because they are emerging processes that also fall under the definition of industrial moderation. Both processes are well examined in the literature [44, 115, 128], are used in some form in industry [7, 43, 85], and were proposed specifically to help address the legitimacy issues plaguing earlier methods [25, 115, 129, 141]. Digital Juries, as described by Fan and Zhang [44], draw legitimacy from democratic norms [25] and use of authentic deliberation [44]. In industry, Digital Juries resemble juries as used on platforms such as League of Legends, Weibo, and even Parler [7, 85]. Expert Panels are representative of bodies of experts like Facebook’s fact-checking program using 3rd party fact-checkers [43] or the Facebook Oversight Board [150], which are intended to be transparent and independent. Because they are an emerging process, platforms are still developing the design of expert panels such as the Facebook Oversight Board, including how they can potentially scale and whether they should conduct policy creation separate from interpretation. However, we chose to include expert panels as a counterpoint to digital juries and limit it to be a process for policy interpretation in line with our other three processes.",0.09429629629629631,0.16745600722222223,0.9062329235061729,0.39714989611111107,,
36,26,3,Section,"(242, 244)",2.2 Legitimacy,0.09429629629629631,0.41890090055555557,0.24451426502057616,0.432737845,,
37,27,3,Paragraph,"[(244, 258), (258, 273), (273, 283), (283, 294), (294, 308), (308, 321)]","2.2.1 What is Legitimacy? Legitimacy can be understood on either a normative or descriptive basis [72, 113]. In its normative sense, legitimacy “refers to some benchmark of acceptability or justification of political power or authority and—possibly—obligation” [113]. Influential examples of normative legitimacy frameworks include constitutional legitimacy [117] and democratic legiti- macy [112], discussed later in the context of emerging content moderation processes. By contrast, in its descriptive sense, legitimacy refers to the acceptance of authority [113, 145].",0.09429629629629631,0.436446285,0.9091585448222221,0.5333054516666667,,
38,27,3,Paragraph,"[(321, 335), (335, 348), (348, 361), (361, 377), (377, 391), (391, 407), (407, 420), (420, 425)]","This study examines legitimacy in its descriptive sense, i.e., as a measurable, subjective, sociolog- ical phenomenon, referred to using the more common phrase perceived legitimacy [137]. However, while we emphasize perceived legitimacy for its established practical benefits, we recognize the role that normative principles like fairness play in shaping attitudes [72]. As such, we will discuss prior work examining both conceptions of legitimacy, using legitimacy to refer to the expansive concept in both its normative and descriptive senses. We use the term democratic legitimacy to refer to the normative concept that political systems derive legitimacy through adherence to democratic norms, procedures, and values [25].",0.09353909465020577,0.5360726738888889,0.9091631823374483,0.6661401738888889,,
39,27,3,Paragraph,"[(425, 438), (438, 451), (451, 469), (469, 482), (482, 495), (495, 506), (506, 520), (520, 536), (536, 549), (549, 561), (561, 573), (573, 586), (586, 599), (599, 613)]","2.2.2 Measuring Perceived Legitimacy. Modern social scientists have contributed a wealth of work on measuring the perceived legitimacy of governance. We draw primarily from work studying the perceived legitimacy of the courts. Among the best established of this work is that of law and psychology professor Tom Tyler and political scientist James Gibson. In Tyler’s framework, fair procedure, quality of decision making, quality of treatment, and motive-based trust contribute to greater perceived legitimacy, while perceived legitimacy in turn fosters compliance, cooperation, and empowerment [136]. Tyler also highlights that, to a plurality, perceived legitimacy is analogous to obtaining the person’s desired outcome [138], implying that there is a limited extent to which process design can create perceived legitimacy at all. While Tyler examines individuals’ interactions with the state, Gibson instead frames perceived legitimacy around institutions. Gibson measures the legitimacy of institutions like courts through procedural values like trustworthiness and neutrality. In addition, he measures institutional commitment, the extent to which people support an institution’s existence, and decisional jurisdiction, the support for the institution’s power over a particular application [55]. Gibson places special emphasis on “diffuse support,” a “reservoir of",0.09353909465020577,0.6805310072222223,0.907964715377778,0.9102248961111111,,
40,28,3,Footer,"[(613, 627)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.09429629629629631,0.9340192225,0.7380540648148148,0.9450888058333333,,
41,29,4,Header,"[(0, 8), (8, 9)]",Comparing The Perceived Legitimacy of Content Moderation Processes 82:5,0.09429629629629631,0.08305529208333332,0.9057049543209879,0.09412487541666666,,
42,30,4,Paragraph,"[(9, 25), (25, 43), (43, 54)]","favorable attitudes or good will that helps members to accept or tolerate outputs to which they are opposed or the effects of which they see as damaging to their wants,” as opposed to “specific support,” or support for a particular action or policy [21, 39].",0.09429629629629631,0.11764211833333336,0.906240816592592,0.16468739611111102,,
43,30,4,Paragraph,"[(54, 68), (68, 81), (81, 94), (94, 110), (110, 123)]","In the domain of content moderation, however, little work exists that measures perceived legiti- macy. Instead, most prior work investigates questions of normative legitimacy, for example outlining fundamental rights and procedural values known to correspond to legitimate governance [129, 130]. Of the studies that take a more descriptive and empirical approach, none have tackled the question of perceived legitimacy head on, focusing instead on adjacent questions [44, 119, 140].",0.09429629629629631,0.16745600722222223,0.9091613989090531,0.24770961833333335,,
44,30,4,Paragraph,"[(123, 137), (137, 149), (149, 162), (162, 166)]","In the absence of an established measure of perceived legitimacy of content moderation, we select Gibson’s formulation of institutional legitimacy as our overarching framework for measuring perceived legitimacy. In addition, we follow Gibson in using population-wide measures of attitudes to capture “diffuse support.”",0.09429629629629631,0.2504768405555555,0.9057062011358026,0.31412767388888885,,
45,31,4,Section,"(166, 174)",2.3 Studying the Legitimacy of Content Moderation Processes,0.09429629629629631,0.33408284499999996,0.6825611773662549,0.3479197894444444,,
46,32,4,Paragraph,"[(174, 190), (190, 205), (205, 219), (219, 233)]","From prior work, we can conclude that while legitimacy is broadly accepted as an important and desirable quality in content moderation systems and a variety of perspectives exist regarding how it can be accrued, the impact of specific processes on perceived legitimacy remains largely unknown. This missing data in the literature motivates the primary research question of our study:",0.09429629629629631,0.35162822944444444,0.9085063856296295,0.41527906277777776,,
47,33,4,List,"[(233, 243), (243, 245)]",RQ1: How do content moderation processes impact levels of perceived institutional legitimacy?,0.17659876543209876,0.4419288341666667,0.8234015720164608,0.4723699452777778,,
48,34,4,Paragraph,"[(245, 260), (260, 275), (275, 292), (292, 307), (307, 312)]","For those seeking to design legitimate content moderation systems, a major open question is the extent to which process design can create perceived legitimacy at all. Because a legitimate process is most valuable when it can mitigate the negative effects of an unfavorable decision, it is important to contextualize the magnitude of process effects by comparing them with the strength of outcome effects. Thus we also ask:",0.09429629629629631,0.4980560072222222,0.9057078410699588,0.5783096183333333,,
49,35,4,List,"[(312, 324), (324, 334), (334, 339)]",RQ2: To what extent does the alignment of outcome of decisions made by a process with individual preferences influence the perceived insti- tutional legitimacy of that process?,0.17659876543209876,0.6018538341666666,0.8270786485596705,0.6488991119444445,,
50,36,4,Section,"(339, 344)",2.4 Known Determiners of Legitimacy,0.09429629629629631,0.6872675672222223,0.4631994847736625,0.7011045116666667,,
51,37,4,Paragraph,"[(344, 357), (357, 370), (370, 384), (384, 400), (400, 404)]","Academics have proposed a plethora of principles and frameworks that contribute to legitimate governance, including transparency and public participation [49, 62, 68, 101, 130], adherence to established legal principles [12, 83], and upholding individual rights [26, 76]. However, to develop hypotheses for RQ1 , we focus our discussion on prior work examining the factors that differ between the four processes.",0.09357818930041152,0.7048129516666667,0.9060895009794238,0.7850665627777779,,
52,37,4,Paragraph,"[(404, 418), (418, 431), (431, 448), (448, 462), (462, 474), (474, 485), (485, 499)]","2.4.1 Independence. Among a large space of dispute resolution processes, prior work shows a consistent preference among litigants for greater decision control by an impartial third-party [70, 123]. National high courts enjoy special legitimacy [51], and it is often taken for granted that their greater independence contributes to public trust [93]. Multiple empirical studies also find support for independence conferring greater perceived legitimacy to political institutions and courts [20, 54]. Consequently, in the domain of content moderation, decision-making by independent bodies commonly features in high level frameworks designed to enhance legitimacy, such as FAITE [135],",0.09382510288065844,0.7976615627777779,0.9088594094090535,0.9111248961111111,,
53,38,4,Footer,"[(499, 513)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.26194238683127574,0.9340206113888889,0.9057001553497942,0.9450901947222222,,
54,39,5,Header,"[(0, 1), (1, 6)]","82:6 Pan, Yakhmi, Iyer, et. al.",0.09429629629629631,0.08305529208333332,0.9057092407407409,0.09412487541666666,,
55,40,5,Paragraph,"[(6, 21), (21, 25)]","national social media councils (SMCs) [78], and policy proposals by the Cato Institute and the Bookings Institute [102, 118].",0.09429629629629631,0.11764211833333336,0.9057063745185185,0.14808322944444446,,
56,40,5,Paragraph,"[(25, 41), (41, 55), (55, 68), (68, 83), (83, 97), (97, 110), (110, 123), (123, 124)]","Among the four moderation processes in this study, we consider the digital jury to have high independence by analogy with criminal juries, which serve as an independent check on government power [126]. Additionally, we expect jury members’ loose and impersonal relationship with the platform would limit the platform’s influence over their decisions. We accept the judgment of prior work that expert panels can benefit from independence [122], but note that potential platform influence over the body and its composition may limit practical independence. Conversely, we deem human contractors and algorithmic moderation to have no practical independence from the platform.",0.09353909465020577,0.15085045166666664,0.9061006022222223,0.2809193405555555,,
57,40,5,Paragraph,"[(124, 135), (135, 148), (148, 154)]","Due to the greater independence of the deliberative bodies, we hypothesize: H1.1: The expert panel and digital jury will be perceived as more legitimate than the paid contractor and algorithm.",0.1147962962962963,0.28368656277777765,0.8234084212427981,0.3507235072222222,,
58,40,5,Paragraph,"[(154, 168), (168, 180), (180, 193), (193, 206), (206, 224), (224, 243), (243, 257), (257, 272), (272, 286), (286, 299), (299, 314), (314, 327), (327, 332)]","2.4.2 Automated Decision Making. As the use of Algorithmic Decision Making (ADS) has grown, researchers have studied its characteristics relative to human decision making from multiple perspectives [23]. ADS is often evaluated according to to specific normative criteria, including fairness [14, 71], accountability [147], explainability [8, 103], and contestability [67, 140]. Such inquiry is motivated in part by evidence that ADS can be biased and can cause various types of harms [13, 15, 31, 109], and in part by application of theories of justice [18, 75, 98]. Despite major theoretical and practical issues commonly known in academia, prior work shows that perception of the trustworthiness of algorithms relative to humans can be favorable, though it is highly dependent on context, subjectivity of the domain, and performance [11, 89, 95]. Moreover, public perceptions of algorithms are subject to cognitive biases, including overconfidence in their capabilities [143], outcome favorability bias [41, 144], excessive aversion to mistakes [35], and folk theories [40]. In general, algorithms tend to benefit from being perceived as impartial, objective, and authoritative by the public [57, 127].",0.09429629629629631,0.3845268405555556,0.9079585229958848,0.5976165627777777,,
59,40,5,Paragraph,"[(332, 344), (344, 359), (359, 373), (373, 384)]","In this study, algorithmic moderation embodies automated judgment, standing in contrast to deliberative bodies like the expert panel and digital jury. While paid contractors can exercise human judgment, we assess that because paid contractors are given extremely limited time and detailed guidelines to make decisions [56], their decisions involve significantly less discretion.",0.09429629629629631,0.600383785,0.9057062011358025,0.6640332294444444,,
60,40,5,Paragraph,"[(384, 396), (396, 412), (412, 426), (426, 432)]","For highly disagreed-upon posts, we anticipate that perceptions of algorithms’ impartiality will outweigh concerns about their lack of ability in a subjective domain and the larger penalties they receive for poor performance. Thus, making a direct comparison between the automated and human processes with low independence, we hypothesize:",0.09429629629629631,0.6668018405555556,0.9062404886057611,0.7304512849999999,,
61,41,5,List,"[(432, 445), (445, 446)]",H1.2: The algorithm will be perceived as more legitimate than the paid con- tractor.,0.17659876543209876,0.7532115627777778,0.8268612158353907,0.7836526738888889,,
62,42,5,Paragraph,"[(446, 461), (461, 476), (476, 493), (493, 505), (505, 520), (520, 534)]","2.4.3 Democratic Legitimacy vs. Expertise. The debate over judge vs. jury trials in the judicial system can be understood as a debate over democratic vs. expert authority. Juries, despite well known drawbacks [82], have long been justified on the grounds that they bind the legal system to community norms and provide legitimacy through democratic representation and the exercise of popular sovereignty [45, 120, 126]. Surveys in the US have consistently found broad public support for juries as an institution (“diffuse support”) [65]. However, little rigorous empirical work exists",0.09429629629629631,0.8143490627777779,0.9057077577695472,0.9112068405555556,,
63,43,5,Footer,"[(534, 548)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.09429629629629631,0.9340192225,0.7380540648148148,0.9450888058333333,,
64,44,6,Header,"[(0, 8), (8, 9)]",Comparing The Perceived Legitimacy of Content Moderation Processes 82:7,0.09429629629629631,0.08305529208333332,0.9057049543209879,0.09412487541666666,,
65,45,6,Paragraph,"[(9, 24), (24, 39), (39, 51)]","that compares the perceived legitimacy of juries to judges [82, 126]. Nevertheless, surveys tend to show a preference for juries over judges [126] and some empirical evidence of perceived legitimacy benefits of citizen participation have been noted in multiple countries [17, 99].",0.09429629629629631,0.11764211833333336,0.9062382247572015,0.16468739611111102,,
66,45,6,Paragraph,"[(51, 68), (68, 85), (85, 98), (98, 113), (113, 128), (128, 142), (142, 144)]","Prior work on the perceived legitimacy of expert authority is mixed. On the one hand, public trust in experts appears pervasive [50, 133], and expertise has traditionally been seen as a way to establish legitimate authority [47, 146]. However, critiques of expert authority are common, with scholars pointing to unequal relationships between experts and the public and other issues [46, 64, 134]. Steven Turner resolves this tension by noting that claims to cognitive authority must be legitimated through acceptance by the public, observing that across fields experts achieve varying levels of success [134].",0.09429629629629631,0.16745600722222223,0.9088605488724281,0.2809193405555555,,
67,45,6,Paragraph,"[(144, 158), (158, 170), (170, 181), (181, 186)]","In this study, the expert panel embodies expert knowledge and judgment, while the digital jury represents democratic participation. Contractors and algorithms, though they may act in accordance with expert-designed guidelines, do not exercise sufficient individual discretion to represent either type of knowledge.",0.09429629629629631,0.2836865627777778,0.9057062011358022,0.34733600722222224,,
68,45,6,Paragraph,"[(186, 200), (200, 215), (215, 228), (228, 242), (242, 255), (255, 256)]","Prior work generally supports the idea that juries are perceived as more legitimate decision makers, and suggests that the benefits of democratic legitimacy extend to the domain of content moderation [44]. Moreover, because the domain of content moderation is relatively novel, it is reasonable to expect that the legitimation process of experts among the public—which can lag legitimation among professionals by decades [134]—is still in its infancy. Consequently, we hypothesize:",0.09429629629629631,0.3501032294444444,0.9057115857119342,0.4469623961111111,,
69,46,6,List,"[(256, 269), (269, 270)]",H1.3: The digital jury will be perceived as more legitimate than the expert panel.,0.17659876543209876,0.4820698961111111,0.8233982756707815,0.5125110072222222,,
70,47,6,Paragraph,"[(270, 282)]","In the following subsection, we review prior work relating to RQ2 .",0.11479629629629629,0.5533323961111111,0.6754295720164608,0.5703380008333333,,
71,47,6,Paragraph,"[(282, 296), (296, 311), (311, 325), (325, 339), (339, 352), (352, 363), (363, 376), (376, 392), (392, 405), (405, 421), (421, 434)]","2.4.4 Role of Pre-Existing Views. While much work on perceived legitimacy is concerned with its ability to promote the acceptance of adverse or unpopular outcomes, prior work suggests that perceived legitimacy is itself shaped by alignment with individual preferences and beliefs. A large body of work finds evidence for various confirmation or congeniality biases [19, 81] whereby pre-existing views affect how information is collected [80], interpreted [96], and evaluated [38]. Similarly, motivated reasoning theory describes mechanisms by which directional goals bias cognitive processes [87]. These biases can be strongly mediated by partisan identification and cues [58, 91]. There is some indication that these cognitive effects may extend to perception of legitimacy. While Gibson finds that controversial decisions do not necessarily impair the legitimacy of an institution like the Supreme Court [53], other work finds that strongly held moral convictions do magnify the effect of outcomes on perceived legitimacy of the court [125].",0.09429629629629631,0.5854754516666667,0.9088605488724281,0.7653568405555556,,
72,47,6,Paragraph,"[(434, 441)]","Based on this prior work, we hypothesize:",0.1147962962962963,0.7681240627777778,0.46695165720164605,0.7819610072222222,,
73,48,6,List,"[(441, 451), (451, 461), (461, 475), (475, 486)]","H2: Users will report higher perceived legitimacy when content moderation systems make decisions that align with their individual normative preferences about whether a post should stay up or be taken down, and this association will be at least as strong as that of process factors.",0.17584156378600824,0.8170685072222222,0.8234027361481484,0.8807179516666667,,
74,49,6,Footer,"[(486, 500)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.26194238683127574,0.9340192225,0.9057001553497942,0.9450888058333333,,
75,50,7,Header,"[(0, 1), (1, 6)]","82:8 Pan, Yakhmi, Iyer, et. al.",0.09429629629629631,0.08305529208333332,0.9057092407407409,0.09412487541666666,,
76,51,7,Section,"(6, 8)",3 METHODS,0.09429629629629636,0.1208522894444444,0.22747944897119346,0.13468923388888893,,
77,52,7,Paragraph,"[(8, 22), (22, 38), (38, 53), (53, 66), (66, 80), (80, 95), (95, 111), (111, 125), (125, 132)]","This study records and analyzes how US Facebook users perceive the institutional legitimacy of various content moderation processes in an online survey setting. In contrast to prior work [73, 119], we examine the attitudes of users who are not directly involved in content takedown decisions (i.e., bystanders). The literature on legitimacy indicates that public attitudes (i.e., “diffuse support”) are what determine the legitimacy of institutions [21]. Moreover, in online communities, the vast majority of users are never involved in content moderation disputes [108]. We designed the survey around Facebook due to the platform’s scale [28], broad adoption in the USA [27], and representative user base [111], and we recruited participants from Amazon Mechanical Turk (AMT), following a common practice in political science studies [30].",0.09353909465020577,0.13839767388888902,0.9079582066831275,0.28506934055555555,,
78,53,7,Section,"(132, 134)",3.1 Materials,0.09429629629629631,0.3064481227777778,0.22846340946502058,0.3202850672222222,,
79,54,7,Paragraph,"[(134, 150), (150, 162), (162, 177), (177, 194), (194, 202)]","We followed the example set by prior work in collecting real social media posts rather than synthesizing controlled examples [44]. This approach mitigates potential biases in post creation and improves the ecological validity of the study, as prior work suggests that hypothetical choices can differ from choices made in concrete situations [86]. To reduce the impact of biases in post selection, we employed a two-stage strategy, described below.",0.0933127572016461,0.3239935072222222,0.9056997203176952,0.40424850722222216,,
80,54,7,Paragraph,"[(202, 219), (219, 230), (230, 245), (245, 261), (261, 275), (275, 288), (288, 300), (300, 316), (316, 330), (330, 344), (344, 355), (355, 373), (373, 389), (389, 391)]","We first compiled a list of Facebook posts representing a wide array of topics common in takedown decisions (e.g., racism, protest, vaccination, electoral fraud, government conspiracy) and viewpoints (e.g., both liberal and conservative), taking care to avoid specific posts that participants were likely to have already encountered in the media. We collected posts that might be viewed as violating Facebook’s Community Standards [3] in three of its categories: inciting violence, hate speech, and misinformation. These categories were chosen for their high frequency and prominence in public disagreements about content moderation. We collected 58 candidate posts from three sources: public Facebook groups, low-traffic news articles, and the Plain View Project (PVP) [1]. The PVP is a journalistic database of Facebook posts authored by police officers expressing themes of violence, racism, and bigotry. To find Facebook groups and news articles, we identified common topics within each category that elicited public disagreement (e.g., anti-vaccination in misinformation). We then used these topics as search terms on Facebook to find groups and on news search engines to find articles containing posts. The resulting posts may or may not have actually been removed by Facebook.",0.0933127572016461,0.4070157294444445,0.908868254552675,0.6367096183333333,,
81,54,7,Paragraph,"[(391, 409), (409, 423), (423, 438), (438, 455), (455, 469), (469, 485), (485, 501), (501, 523), (523, 541), (541, 556)]","To further mitigate bias, we narrowed this broad pool of candidates to nine posts (i.e., 3 in each category of potential infringement) by selecting the posts that were the most disagreed-upon by Facebook user participants on AMT. We ran a pre-survey that asked 56 participants (not eligible for the main survey) their opinion about whether a given post ought to be removed (i.e., normative preference). Responses were recorded on a five-point Likert scale, ranging from strongly disagree (1) to strongly agree (5). For each candidate post, we calculated its disagreement score as a combination of the standard deviation of the responses and the absolute deviation of the median from the neutral response value of 3: 𝑑𝑖𝑠𝑎𝑔𝑟𝑒𝑒𝑚𝑒𝑛𝑡 𝑝𝑜𝑠𝑡 = 𝜎 𝑝𝑜𝑠𝑡 − | 3 − 𝜇 𝑝𝑜𝑠𝑡 | . This formulation was chosen to ensure that posts would not only elicit a wide spread of opinions, but these opinions would be well balanced between favoring taking down and leaving up. 1 The median standard deviation of",0.09353909465020577,0.6394768405555555,0.9069242591522633,0.8027540627777777,,
82,55,7,Footnote,"[(556, 576), (576, 612), (612, 649), (649, 663)]","1 After the study was conducted, we discovered that we mistakenly included a post (Post 5 in the Supplementary Materials) that was not among the top 3 posts by disagreement score in its category—inciting violence. Although the study was designed around highly disagreed-upon content to enhance our ability to measure effects of process on perceived legitimacy, content moderation processes also deal with content for which opinions are more homogeneous. After performing additional analysis on a dataset that excluded the post in question, we found no meaningful change in the magnitude or direction of effects but observed higher p-values due to the loss of about 11% of data.",0.09400411522633745,0.8286202133333334,0.9075088864197528,0.9104068613888889,,
83,56,7,Footer,"[(663, 677)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.09429629629629631,0.9340192225,0.7380540648148148,0.9450888058333333,,
84,57,8,Header,"[(0, 8), (8, 9)]",Comparing The Perceived Legitimacy of Content Moderation Processes 82:9,0.09429629629629631,0.08305529208333332,0.9057049543209879,0.09412487541666666,,
85,58,8,Paragraph,"[(9, 31), (31, 39)]","responses for the final nine posts was 1 . 5, and the median of the posts’ median response was 3 . 0. These posts are available in the Supplementary Materials.",0.09368106995884774,0.11764211833333336,0.9088607122962963,0.14808322944444446,,
86,59,8,Section,"(39, 42)",3.2 Experimental Design,0.09429629629629631,0.1713231227777778,0.3365965679012346,0.18516006722222234,,
87,60,8,Paragraph,"[(42, 54), (54, 70), (70, 81), (81, 94), (94, 108), (108, 123), (123, 139), (139, 152), (152, 162)]","We constructed a within-subjects survey experiment to assess the perceived institutional legitimacy of content moderation decisions made by a paid contractor, an algorithm, an expert panel, and a digital jury. Participants were given 4 randomly constructed content moderation decisions—this randomization exposed participants to many many combinations of posts and processes to help mitigate biases introduced by individual posts. For each decision, participants were asked to answer several questions regarding their attitudes toward the post and the decision outcome. At the end, participants were asked to discuss the four processes on a comparative basis. The study design was reviewed and approved by our institution’s institutional review board (IRB) under protocol #57848. Selected screenshots of the survey are available in supplementary materials.",0.0933127572016461,0.18886850722222226,0.9088694670518515,0.33554156277777775,,
88,60,8,Paragraph,"[(162, 178), (178, 193), (193, 206), (206, 218), (218, 233), (233, 250), (250, 266), (266, 269)]","3.2.1 Participants. The survey was sent to US Facebook users on AMT. AMT allows only workers 18 years or older, and gives workers the option to self-report being Facebook users. Participants were required to go through an IRB-approved consent process with appropriate content warnings and resources. Participants were informed that neither the moderation decisions nor processes were real only in the survey debrief, to improve the survey realism. Participants were compensated $1.82 for the 15 minutes spent completing the survey, based on the 2020 federal minimum wage of $7.25/hr [110], a rate above the mean and median hourly wages for AMT workers ($3.13/hr and $1.77/hr, respectively) [66].",0.09353909465020577,0.3514198961111111,0.9057107043106996,0.48148739611111113,,
89,60,8,Paragraph,"[(269, 288), (288, 300), (300, 318), (318, 326)]","We set a target sample size of 100 participants based on a small pilot study in which we already observed significant outcome-preference alignment effects, and power analysis aiming to detect an effect size of 0.5 points (out of 20) for process effect. After the data validation described below, 93 responses remained. No additional stratified (sub)sampling was performed.",0.09429629629629631,0.4842546183333333,0.9062360843609053,0.5479054516666666,,
90,60,8,Paragraph,"[(326, 339), (339, 353), (353, 366), (366, 385), (385, 400), (400, 417), (417, 432), (432, 447), (447, 464)]","Participants were 57% female and 43% male. Participants were also well balanced between political affiliations, with 35% identifying as liberal, 31% as conservative, 31% as independent, and a remaining 2% refraining from reporting affiliation. Roughly 60% of participants were between the ages of 25 and 44, with 35% 45 or older. This age distribution mirrors that of US Facebook users [27], although it underrepresents the 18-24 age group. The survey population reported as 80% White, 11% Asian, 4% Mixed Race, 3% Black, and 1% Native American, with a further 1% declining to report. Additionally, 11% of participants reported as Hispanic or Latino, across all race categories. Compared to the US population, our survey population was more educated, with only 23% reporting highest attainment as high school, 38% with a Bachelor’s degree, and 18% with a Master’s or higher.",0.0933127572016461,0.5506726738888889,0.9088528217201646,0.6973443405555555,,
91,60,8,Paragraph,"[(464, 475), (475, 494), (494, 510), (510, 526), (526, 543), (543, 557), (557, 571), (571, 585), (585, 601), (601, 616), (616, 624)]","3.2.2 Experimental Manipulation. Each participant was shown four moderation decisions consist- ing of 1) a post randomly selected from the nine, 2) one of the four moderation processes, 3) a random decision outcome—taken down or left up, and 4) a brief indication of the violation category if the post was taken down. Each moderation process was shown exactly once, in random order, and posts were sampled such that each of the three categories of content violation would be seen at least once in the four decisions. The moderation process descriptions shown to participants were intentionally kept short to allow pre-existing attitudes and assumptions to be captured in responses, and to approximate the opaque nature of content moderation as practiced today [116]. These descriptions are provided in Appendix A. From our pilot studies, we found that the descrip- tions were adequate for users to be able to understand and differentiate between the moderation processes, aligning with prior work [11, 89, 95].",0.09353909465020577,0.7132240627777777,0.9091766216806586,0.8931040627777778,,
92,61,8,Footer,"[(624, 638)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.26194238683127574,0.9340192225,0.9057001553497942,0.9450888058333333,,
93,62,9,Header,"[(0, 1), (1, 6)]","82:10 Pan, Yakhmi, Iyer, et. al.",0.09429629629629631,0.08305529208333332,0.9057092407407409,0.09412487541666666,,
94,63,9,Table,"[(6, 10), (10, 11), (11, 13)]",Measure of Institutional Legitimacy Question Outcome Satisfaction,0.09429629629629631,0.12361756722222215,0.500405490946502,0.15779572944444437,,
95,64,9,Paragraph,"[(13, 22), (22, 26)]",I am satisfied with the way the [moderation process] handled this moderation decision.,0.4288456790123457,0.143958785,0.8954545045925927,0.17440128499999996,,
96,65,9,Table,"[(26, 27)]",Trustworthiness,0.09429629629629631,0.1771685072222223,0.23153828600823043,0.1910054516666667,,
97,66,9,Paragraph,"[(27, 32)]",[Moderation process] can be trusted.,0.42884286419753087,0.1771685072222223,0.7364945119341565,0.1910054516666667,,
98,67,9,Table,"[(32, 35)]",Fairness and Impartiality,0.09429629629629631,0.19377267388888902,0.3034698979423868,0.2076096183333334,,
99,68,9,Paragraph,"[(35, 42)]",[Moderation process] can be fair and impartial.,0.42884286419753087,0.19377267388888902,0.8235545164609055,0.2076096183333334,,
100,69,9,Table,"[(42, 44)]",Institutional Commitment,0.09429629629629631,0.21037684055555575,0.3132070069958848,0.22421378500000014,,
101,70,9,Paragraph,"[(44, 51), (51, 55)]",Facebook should keep using [moderation process] to make content moderation decisions.,0.4288456790123457,0.21037684055555558,0.8954545045925927,0.2408179516666667,,
102,71,9,Table,"[(55, 57)]",Decisional Jurisdiction,0.09429629629629631,0.24358517388888903,0.28403667818930045,0.2574221183333334,,
103,72,9,Paragraph,"[(57, 64), (64, 66)]",[Moderation process] should be the authority making moderation decisions.,0.4288456790123457,0.24358517388888887,0.8954545045925923,0.2740276738888888,,
104,73,9,Caption,"[(66, 82), (82, 99), (99, 109)]","Table 1. Questions used to measure each aspect of institutional legitimacy in the survey experiment. Users responded to these questions on a 5 point Likert scale. [Moderation process] should be replaced with the moderation process in question (e.g., digital juries of Facebook users).",0.09379835390946502,0.28209236000000004,0.9057067899259263,0.32498736,Table,1.0
105,74,9,Paragraph,"[(109, 121), (121, 136), (136, 149), (149, 160), (160, 170), (170, 180), (180, 194), (194, 207), (207, 221), (221, 234), (234, 247), (247, 260), (260, 276), (276, 288), (288, 303), (303, 316), (316, 332)]","3.2.3 Measures. The perceived institutional legitimacy of moderation decisions served as the primary quantitative measure of the survey. Five survey questions, given in Table 1, were posed to participants for each moderation decision, corresponding to five component measures of per- ceived institutional legitimacy—outcome satisfaction, users’ trust in the process, perceived fairness and impartiality, institutional commitment, and decisional jurisdiction. The questions assessing trustworthiness, institutional commitment, and decisional jurisdiction were adapted from Gibson’s work surveying the institutional legitimacy of national high courts [51, 55], while the question assessing fairness and impartiality was adapted from a study measuring perceived legitimacy of state Supreme Courts [54]. These questions were modified to fit the domain, and institutional commitment and decisional jurisdiction were flipped from negative to affirmative to better suit our hypothetical setting. We also included a question assessing outcome satisfaction (found to be positively correlated with institutional legitimacy [55]) using similar language to prior work evaluating content moderation [44]. As in prior empirical work [44, 51, 55], terms like fairness and impartiality were not rigorously defined to avoid unduly influencing participants with prescriptive normative criteria. The responses to these questions were captured on a five point Likert scale, and we calculated Cronbach’s alpha (a common measure of internal consistency) between these five measures in our data as 0.92. These component measures were summed to create a composite",0.09353909465020577,0.37279906277777775,0.9091590794238684,0.6523068405555554,,
106,74,9,Paragraph,"[(332, 344)]","measure.Inaddition to this quantitative measure, the survey also collected qualitative data through",0.09429629629629631,0.6550740627777778,0.905706201135802,0.6855151738888888,,
107,74,9,Paragraph,"[(344, 357), (357, 370), (370, 386), (386, 403), (403, 416), (416, 430), (430, 436)]","free response questions. Participants were randomly asked to elaborate on their responses to quantitative questions 50% of the time. Additionally, after answering questions about the four moderation decisions, all participants were asked 1) to select the process they saw as the most trusted, least trusted, most fair and impartial, and least fair and impartial, and 2) to provide a brief rationale(s) behind their choices. These comparative questions were included not only to corroborate quantitative results, but also because prior research shows that people can be more effective in making comparative judgments [148].",0.09429629629629631,0.688283785,0.9060944524691354,0.8017471183333333,,
108,74,9,Paragraph,"[(436, 447), (447, 460), (460, 475), (475, 479)]","Demographic information, including age, gender, race, ethnicity, education level, work expe- rience, political affiliation, income, and Facebook usage, was also collected primarily to assess the representativeness of the participant group, and in limited cases to test for association with perceived legitimacy (detailed below).",0.09429629629629631,0.8045143405555556,0.9091771217777774,0.868163785,,
109,74,9,Paragraph,"[(479, 494), (494, 507)]","3.2.4 Data Validation. In order to validate responses, users were asked to answer attention check questions (repeating back details about the moderation process and outcome). Any participants that",0.09429629629629631,0.8807073961111112,0.9062268407814811,0.9111485072222223,,
110,75,9,Footer,"[(507, 521)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.09429629629629631,0.9340192225,0.7380540648148148,0.9450888058333333,,
111,76,10,Header,"[(0, 8), (8, 9)]",Comparing The Perceived Legitimacy of Content Moderation Processes 82:11,0.09429629629629631,0.08305529208333332,0.9057049543209879,0.09412487541666666,,
112,77,10,Paragraph,"[(9, 23), (23, 26)]","failed these attention check questions were removed from the dataset. In addition, any spam-like submissions were removed.",0.09429629629629631,0.11764211833333336,0.9057027541958845,0.14808322944444446,,
113,78,10,Section,"(26, 38)",3.2.5 Quantitative Modeling. Quantitative responses were analyzed using a linear mixed effects,0.09429629629629631,0.16108100722222235,0.9057070971144034,0.17818347055555567,,
114,79,10,Paragraph,"[(38, 52), (52, 63), (63, 76), (76, 91), (91, 106), (106, 121), (121, 132), (132, 145), (145, 160), (160, 176), (176, 192), (192, 207), (207, 214)]","(LME) model in which the degree of alignment of individual normative preference with outcome (Alignment), content moderation process (Process), Gender, and Political Affiliation serve as explanatory variables, and measures of perceived legitimacy, as the response variable (as described in Section 3.2.3). The inclusion of Alignment and Process relate to RQ2 and RQ1 respectively, while Gender and Political Affiliation are included because they have been shown to relate to perceived legitimacy in prior work [52, 136]. We intentionally do not control for participants’ prior exposure to content moderation, as perceived legitimacy measures population-wide attitudes—it is a sociological phenomenon that must be assessed within a representative population sample. In this model, each participant is given a random intercept and slope for decision outcome, allowing for the possibility that each participant may have a different inclination to take down or leave up posts. Additionally, each post is given a random intercept and slope for decision outcome and political affiliation, as specific posts may be more or less objectionable across the population, and many posts have a significant political dimension.",0.09353909465020577,0.1776851738888889,0.9079635664761316,0.39077489611111105,,
115,79,10,Paragraph,"[(214, 228), (228, 243), (243, 258), (258, 266)]","The composite measure of perceived legitimacy serves as the dependent variable for the primary model, which is used for all hypothesis tests. To further understand how the explanatory variables relate to individual measures of perceived legitimacy, parallel submodels were also fit with each of the five perceived legitimacy measures as dependent variables.",0.09429629629629631,0.3935421183333333,0.9062301600987651,0.4571929516666666,,
116,79,10,Paragraph,"[(266, 279), (279, 293), (293, 306), (306, 323), (323, 337), (337, 349), (349, 362), (362, 379), (379, 394)]","3.2.6 Qualitative Coding. To analyze the four final comparative free response questions, two co-authors identified the moderation process named by each participant. If no process could be identified, the entire response was excluded from analysis. If multiple processes were indicated, only the process identified as a first choice was coded if a relative ordering was given, otherwise all processes were coded. The same two co-authors then performed an open coding procedure to identify all meaningfully distinguishable attitudes expressed by participants in their answers. Noting that participants frequently hedged their answers and expressed multiple attitudes at a time, one co-author then developed a framework of axial codes in which attitudes were coded as a series of ( 𝑟𝑜𝑙𝑒,𝑠𝑢𝑏𝑗𝑒𝑐𝑡, 𝑝𝑟𝑒𝑑𝑖𝑐𝑎𝑡𝑒 ) triples, each component of which is defined as follows:",0.09429629629629631,0.4701893405555555,0.9088641372658435,0.6189365488888889,,
117,80,10,List,"[(394, 411), (411, 417), (417, 431), (431, 442)]","(1) role : Indicates whether the attitude served as a rationale for the answer, qualification of the answer, or condition for the answer. (2) subject : Indicates to which of the four moderation process(es) the attitude pertains. (3) predicate : Indicates the idea being expressed about the subject.",0.11456995884773662,0.624558785,0.9057103572983538,0.6914184005555556,,
118,81,10,Paragraph,"[(442, 460), (460, 478), (478, 497), (497, 513), (513, 527), (527, 543), (543, 554), (554, 569), (569, 582)]","For example, the attitude expressed in, “I think a panel of experts can be most trusted because they have the training needed to make good decisions, but the platform can select experts in a biased way,” might be coded as: [( 𝑟𝑎𝑡𝑖𝑜𝑛𝑎𝑙𝑒, 𝐸𝑥𝑝𝑒𝑟𝑡, Code 8 : ""has necessary training"" ) , ( 𝑞𝑢𝑎𝑙𝑖𝑓 𝑖𝑐𝑎𝑡𝑖𝑜𝑛, 𝐸𝑥𝑝𝑒𝑟𝑡, Code 13 : ""controlled by platform"" )] . The two co-authors independently rated all responses, and Cohen’s kappa, a metric of inter-rater reliability, was calculated separately for each possible code. Across processes we calculated a mean kappa of 0.99, and across attitude triples we calculated a frequency-weighted average kappa of 0.61. Subsequently, the two co-authors discussed inconsis- tencies and reached unanimous agreement on the final coding of each response. The full attitude coding scheme contains approximately 50 distinct predicates, which are given in Appendix B.",0.09357818930041152,0.6959046183333334,0.9091709689465022,0.8425776738888888,,
119,82,10,Section,"(582, 584)",4 RESULTS,0.09429629629629631,0.8629356227777778,0.21294553251028805,0.8767725672222222,,
120,83,10,Paragraph,"[(584, 597), (597, 607)]","The primary quantitative model of survey responses estimates the effect on perceived institutional legitimacy of Alignment, Process, Gender, and Political Affiliation. Regression coefficients",0.09368106995884774,0.8804810072222223,0.9057055089300411,0.9109221183333334,,
121,83,10,Paragraph,"[(607, 621)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.26194238683127574,0.9340192225,0.9057001553497942,0.9450888058333333,,
122,84,11,Header,"[(0, 1), (1, 6)]","82:12 Pan, Yakhmi, Iyer, et. al.",0.09429629629629631,0.08305529208333332,0.9057092407407409,0.09412487541666666,,
123,85,11,Table,"[(6, 7), (7, 10), (10, 12), (12, 13), (13, 14), (14, 16), (16, 17), (17, 18), (18, 19), (19, 21), (21, 22), (22, 24), (24, 25), (25, 27), (27, 28), (28, 30), (30, 31), (31, 32), (32, 33), (33, 34), (34, 35), (35, 36), (36, 37), (37, 38), (38, 39), (39, 40), (40, 41), (41, 42), (42, 43), (43, 44), (44, 45), (45, 46), (46, 48), (48, 49), (49, 51), (51, 52), (52, 53), (53, 54), (54, 55), (55, 58), (58, 59), (59, 62), (62, 63), (63, 66), (66, 67), (67, 68), (68, 69), (69, 71), (71, 72)]",Variable Alternative: No Interactions Primary Model Alignment 1.86*** 1.87*** (0.15) (0.15) Algorithm -0.66 -0.68* (0.34) (0.34) Expert Panel 1.18*** 1.14*** (0.34) (0.34) Digital Jury -0.56 -0.55 (0.34) (0.34) Male -0.52 -0.45 (0.67) (0.67) Conservative -1.04 -1.10 (0.84) (0.84) Independent -2.14* -2.18** (0.83) (0.82) Unreported Affiliation -3.80 -3.78 (2.32) (2.32) Alignment * Algorithm 0.06(0.26) Alignment * Expert 0.15(0.25) Alignment * Jury 0.17(0.24) Constant 17.68*** 17.71*** (0.64) (0.65),0.09429629629629631,0.12361756722222215,0.894522667078189,0.5396971183333333,,
124,86,11,Caption,"[(72, 88), (88, 103), (103, 117), (117, 131), (131, 153)]","Table 2. Determinants of perceived legitimacy as modeled by primary and alternative LME models. Process is modeled using deviation contrasts such that the Constant reflects the mean across processes, and coefficients are comparable between models. Significance levels are indicated for readability purposes only and are calculated with t-tests using Satterthwaite’s method [97]. These levels do not constitute formal hypothesis tests. | 𝑝 < 0 . 001 *** , 𝑝 < 0 . 01 ** , 𝑝 < 0 . 05 *",0.09379835390946502,0.5477631933333333,0.9057082658765429,0.6220008755555556,Table,0.0
125,87,11,Paragraph,"[(153, 168), (168, 183), (183, 200), (200, 214), (214, 230), (230, 236)]","from this model are presented in Table 2, where coefficients from an alternative model without interaction terms are also given for comparison. While statistical tests do not show greater explana- tory power for the primary model versus this alternative, the full model is used for hypothesis tests. Results from the parallel submodels are found to be consistent with the primary model—suggesting that the composite measure is not dominated by a subset of measures. Regression results from the submodels are given in Appendix C.",0.09429629629629631,0.6455129516666667,0.9091742488148146,0.7423721183333334,,
126,87,11,Paragraph,"[(236, 253), (253, 268), (268, 279), (279, 289)]","The effects of Process and Alignment are discussed in detail below. We do not find evidence that Gender is associated with perceived legitimacy. We do find evidence that political affiliation has a statistically significant relationship with perceived legitimacy by ANOVA, but pairwise contrasts are not statistically significant, preventing us from drawing specific conclusions.",0.09429629629629631,0.7451393405555555,0.9056948415135804,0.808788785,,
127,88,11,Section,"(289, 295)",4.1 Perceived Legitimacy of Moderation Processes,0.09429629629629631,0.8295342338888888,0.5741820288065842,0.8433711783333333,,
128,89,11,Paragraph,"[(295, 314), (314, 325), (325, 340), (340, 356)]","To evaluate H1 , we conduct Tukey’s HSD test as a post hoc analysis of the pairwise differences in perceived institutional legitimacy across moderation processes. This test allows for significance testing across more than two groups and makes fewer assumptions than t-tests, which are not universally accepted for LME model parameters [97]. Results are presented in Table 4. From this test,",0.09368106995884774,0.8470796183333332,0.9079567937613168,0.9107290627777778,,
129,90,11,Footer,"[(356, 370)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.09429629629629631,0.9340192225,0.7380540648148148,0.9450888058333333,,
130,91,12,Header,"[(0, 8), (8, 9)]",Comparing The Perceived Legitimacy of Content Moderation Processes 82:13,0.09429629629629631,0.08305529208333332,0.9057049543209879,0.09412487541666666,,
131,92,12,Table,"[(9, 10), (10, 14), (14, 15), (15, 16), (16, 17), (17, 18), (18, 19), (19, 20), (20, 21), (21, 23), (23, 25), (25, 27), (27, 30), (30, 32), (32, 34), (34, 36), (36, 38), (38, 39), (39, 41), (41, 43), (43, 45), (45, 47), (47, 48), (48, 50), (50, 52), (52, 54), (54, 56)]",Process Proportion of Respondents (%) Trustworthiness Impartiality Highest Lowest Highest Lowest Contractor 14% (13) 35% (31) 9% (8) 46% (41) Algorithm 30% (28) 34% (30) 51% (46) 13% (12) Expert 41% (38) 9% (8) 28% (25) 8% (7) Jury 28% (26) 27% (24) 18% (16) 36% (32),0.27362962962962945,0.12361756722222215,0.726370969547325,0.2544360072222223,,
132,93,12,Caption,"[(56, 71), (71, 85)]",Table 3. Proportion of participants indicating each moderation process as ranking the highest and lowest with respect to trustworthiness and impartiality . Raw participant counts are given in parentheses.,0.09363168724279836,0.26250208222222227,0.9057025899193412,0.2931027822222222,Table,1.0
133,94,12,Table,"[(85, 86), (86, 87), (87, 89), (89, 93), (93, 94), (94, 97), (97, 98), (98, 99), (99, 102), (102, 103), (103, 104), (104, 107), (107, 108), (108, 109), (109, 112), (112, 113), (113, 114), (114, 117), (117, 118), (118, 119)]",Contrast Estimate Standard Error Algorithm - Contractor -0.78 0.60 Expert - Contractor 1.02 0.60 Expert - Algorithm 1.81* 0.60 Jury - Contractor -0.66 0.60 Jury - Algorithm 0.13 0.62 Jury - Expert -1.68* 0.61,0.28533744855967075,0.3418342338888889,0.7131962699588477,0.46220327861111105,,
134,95,12,Caption,"[(119, 135)]",Table 4. Tukey’s HSD test results of significance in the difference in mean perceived legitimacy across,0.09379835390946502,0.4671006933333333,0.9056981251687239,0.4795540266666667,Table,2.0
135,96,12,Table,"[(135, 158)]","moderation processes. | 𝑝 < 0 . 001 *** , 𝑝 < 0 . 01 ** , 𝑝 < 0 . 05 *",0.09429629629629631,0.48094738625,0.5323108623456789,0.49567587555555553,,
136,97,12,Paragraph,"[(158, 174), (174, 190), (190, 203), (203, 220), (220, 236), (236, 252), (252, 269), (269, 277)]","we can conclude that decisions made by the expert panel are perceived as more legitimate, according to our definition, than decisions made by both the digital jury and algorithm; however there is not sufficient evidence to draw conclusions about the perceived legitimacy of other moderation processes. Consequently, we find partial support for H1.1 and are able to disprove H1.3 , but do not find evidence to support or disprove H1.2 . To better visualize the varying perceived legitimacy of the four moderation processes, a marginal effects plot is presented in Figure 1. Additionally, a summary of coded free responses to the comparative questions is presented in Table 5 and 6, and corresponding quantitative results are presented in Figure 2.",0.09353909465020577,0.5204907294444444,0.9062382661069959,0.6505582294444444,,
137,97,12,Paragraph,"[(277, 292), (292, 307), (307, 322), (322, 336), (336, 351), (351, 367), (367, 381), (381, 393), (393, 406), (406, 422), (422, 435), (435, 451), (451, 467), (467, 480), (480, 487)]","4.1.1 H1.1. Quantitative results show that the expert panel has higher perceived legitimacy than the algorithm, supporting one component of H1.1 . In free response, an important factor for participants appeared to be whether decisions were made by groups or individuals. 24% of respondents suggested that contractors would make more biased decisions as single individuals, and 24% suggested that contractors would apply their own beliefs and agenda. Moreover, a full 42% of participants expressed support in some form for the idea that groups of moderators can be more trustworthy and/or impartial that single moderators. In contrast to our expectations, qualitative results cast doubt on independence as a major factor driving perceived legitimacy. Many participants acknowledged the greater independence of the two deliberative bodies—25% of participants expressed a belief that paid contractors would carry out the agenda and biases of the platform and 16% expressed concern that the algorithm could be programmed with platform biases, while much smaller proportions expressed similar ideas about expert panels or digital juries (2% for both). However, only 8% of participants selecting expert panels and 6% of those selecting the digital jury as the most impartial process provided independence as a rationale, with similar or smaller proportions among those selecting these processes as the most trustworthy.",0.09429629629629631,0.6642671183333333,0.9060944524691357,0.9105665627777777,,
138,98,12,Footer,"[(487, 501)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.26194238683127574,0.9340192225,0.9057001553497942,0.9450888058333333,,
139,99,13,Header,"[(0, 1), (1, 6)]","82:14 Pan, Yakhmi, Iyer, et. al.",0.09429629629629631,0.08305529208333332,0.9057092407407409,0.09412487541666666,,
140,100,13,Figure,"[(6, 9)]",Content Moderation Process,0.4115034146090535,0.44620011607638893,0.6506395159979423,0.4600890223263889,,
141,101,13,Paragraph,"[(9, 13), (13, 17), (17, 21), (21, 26), (26, 30), (30, 33), (33, 38), (38, 41), (41, 42), (42, 43), (43, 44), (44, 45), (45, 46), (46, 47), (47, 48), (48, 49), (49, 50)]",P e r c e i v e d I n s t i t u t i o n a l L e g i t i m a c y Contractor Algorithm Expert Jury 5 10 15 20 25,0.24575668019547325,0.13536849600657475,0.7085151839241255,0.433372039404809,,
142,102,13,Caption,"[(50, 67), (67, 75)]","Fig. 1. The mean perceived legitimacy of each process is plotted, shown with a 95% confidence interval calculated from variance of the fixed effect estimates.",0.09429629629629631,0.48245624888888883,0.9057067899259258,0.5101304155555556,Figure,0.0
143,103,13,Figure,"[(75, 78)]",Content Moderation Process,0.2378068269127778,0.7355170514990201,0.39048566220552783,0.7443845625833952,,
144,104,13,Paragraph,"[(78, 84), (84, 91), (91, 92)]",T r u s t w o r t h i n e s,0.1348216433709352,0.5993600154896951,0.14795869682926854,0.654923839944389,,
145,104,13,Paragraph,"[(92, 93), (93, 94), (94, 95), (95, 96), (96, 97), (97, 98), (98, 99), (99, 100), (100, 101)]",Contractor Algorithm Expert Jury 1 2 3 4 5,0.15818763224599652,0.5427166652729248,0.43122991082654927,0.7273268376672833,,
146,105,13,Caption,"[(101, 108)]",(a) The mean trustworthiness of each process.,0.12633539094650206,0.7557298600000001,0.46740884938271604,0.7711097266666667,Figure,3.0
147,106,13,Figure,"[(108, 111)]",Content Moderation Process,0.6435105306164814,0.7355170514990201,0.7961893659092315,0.7443845625833952,,
148,107,13,Paragraph,"[(111, 118), (118, 123), (123, 124), (124, 125), (125, 126), (126, 127), (127, 128), (128, 129), (129, 130), (130, 131), (131, 132)]",I m p a r t i a l i t y Contractor Algorithm Expert Jury 1 2 3 4 5,0.5405253470746388,0.5456153444686284,0.8382075829423339,0.7273268376672833,,
149,108,13,Figure,"[(132, 139)]",(b) The mean impartiality of each process.,0.5437510288065843,0.7557298600000001,0.861400618930041,0.7711097266666667,,
150,109,13,Caption,"[(139, 155), (155, 170), (170, 176)]",Fig. 2. Trustworthiness and impartiality of each moderation process. Each mean is shown with a 95% confidence interval calculated from variance of the fixed effect estimates. The Bonferroni correction used for hypothesis tests is not applied here.,0.09429629629629631,0.7875548600000001,0.9063277961481481,0.8304498600000001,,
151,110,13,Footer,"[(176, 190)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.09429629629629631,0.9340192225,0.7380540648148148,0.9450888058333333,,
152,111,14,Header,"[(0, 8), (8, 9)]",Comparing The Perceived Legitimacy of Content Moderation Processes 82:15,0.09429629629629631,0.08305529208333332,0.9057049543209879,0.09412487541666666,,
153,112,14,Table,"[(9, 10), (10, 11), (11, 13), (13, 14), (14, 16), (16, 18), (18, 20), (20, 24), (24, 26), (26, 29), (29, 31), (31, 38), (38, 43), (43, 45), (45, 46), (46, 52), (52, 54), (54, 59), (59, 61), (61, 67), (67, 69), (69, 72), (72, 74), (74, 75), (75, 86), (86, 88), (88, 93), (93, 100), (100, 102), (102, 103), (103, 108), (108, 110), (110, 115), (115, 117), (117, 123), (123, 125), (125, 130), (130, 132)]","Pr. Rationale % (n) Rationale % (n) Highest Trustworthiness Lowest Trustworthiness Contractor It’s their job 38% (5) Single person bias 61% (19) Has necessary training and knowledge 31% (4) Implements platform agenda and biases 39% (12) Algorithm Decides based on logic, data, rules 32% (9) Lacks human factors of cognition 50% (15) Doesn’t apply own beliefs and agenda 18% (5) Generally performs poorly 40% (12) Expert Has necessary training and knowledge 50% (19) Performed worse (in survey) 25% (2) Multiple people helps mitigate bias 26% (10) Applies own beliefs and agenda 13% (1) Jury Multiple people helps mitigate bias 31% (8) Applies own beliefs and agenda 54% (13) Doesn’t apply own beliefs and agenda 12% (3) Random selection process not sufficient 38% (9)",0.10454526748971193,0.12361756722222215,0.9006710162551441,0.3184151947222222,,
154,113,14,Caption,"[(132, 148), (148, 163), (163, 166)]","Table 5. Most frequent rationales given for answer among participants selecting each process as having the highest and the lowest trustworthiness . Proportions are given as percentages, with raw participant counts given in parentheses.",0.09379835390946502,0.3264868044444444,0.9057090233415639,0.36938041555555556,Table,1.0
155,114,14,Table,"[(166, 167), (167, 168), (168, 170), (170, 171), (171, 173), (173, 175), (175, 177), (177, 182), (182, 184), (184, 187), (187, 189), (189, 193), (193, 195), (195, 200), (200, 202), (202, 203), (203, 209), (209, 214), (214, 216), (216, 222), (222, 229), (229, 231), (231, 232), (232, 239), (239, 244), (244, 246), (246, 251), (251, 253), (253, 257), (257, 259), (259, 260), (260, 265), (265, 267), (267, 272), (272, 274), (274, 278), (278, 280), (280, 287)]","Pr. Rationale % (n) Rationale % (n) Highest Impartiality Lowest Impartiality Contractor Faithfully adheres to guidelines 38% (3) Single person bias 41% (17) Is accountable for decisions 25% (2) Applies own beliefs and agenda 34% (14) Algorithm Doesn’t apply own beliefs and agenda 52% (24) Generally performs poorly 50% (6) Decides based on logic, data, rules 37% (17) Lacks human factors of cognition 42% (5) Expert Has necessary training and knowledge 24% (6) Applies own beliefs and agenda 43% (3) Multiple people helps mitigate bias 20% (5) Unaccountable (e.g., lacks oversight) 43% (3) Jury Multiple people helps mitigate bias 44% (7) Applies own beliefs and agenda 56% (18) Is independent of platform 6% (1) Lack necessary training and knowledge 25% (8)",0.10454526748971193,0.4119772894444444,0.8963087804526749,0.6067749169444444,,
156,115,14,Caption,"[(287, 303), (303, 319), (319, 321)]","Table 6. Most frequent rationales given for answer among participants selecting each process as having the highest and the lowest impartiality . Proportions are given as percentages, with raw participant counts given in parentheses.",0.09379835390946502,0.6148451377777777,0.9056977561810702,0.6577401377777777,Table,2.0
157,116,14,Section,"(321, 334)",4.1.2 H1.2. Quantitative estimates of the perceived legitimacy of algorithms and paid contractors,0.09429629629629631,0.6810698961111111,0.9057115257102881,0.6981723594444444,,
158,117,14,Paragraph,"[(334, 345), (345, 359), (359, 374), (374, 388), (388, 402), (402, 417), (417, 430), (430, 446), (446, 459), (459, 466)]","were not statistically distinguishable. However, qualitative analysis of free response provides more clues. Pluralities of respondents designated the paid contractor as the least trustworthy and least impartial decision maker, while a majority (51%) chose the algorithm as the most impartial, suggesting some support for H1.2 . The discrepancy between the quantitative estimates and free response answers for paid contractors is notable. These discrepancies might be due to estimation error and lack of statistical significance, or alternatively by substantive differences in the framing of the quantitative and free response questions. In quantitative questions, participants were asked to provide ratings in isolation, while in free response, they were asked to consider all four processes simultaneously. Moreover, in free response questions, participants were only asked to discuss the most and least trustworthy and impartial processes.",0.09353909465020577,0.6976740627777778,0.9079674827666665,0.860951285,,
159,117,14,Paragraph,"[(466, 478), (478, 492), (492, 506)]","Participants were concerned with paid contractors implementing their own agenda and biases (24%), despite the limited role of personal interpretation in contractor moderation in most plat- forms [10, 107], or implementing the biases of the platform (25%). Interestingly, some participants",0.09368106995884774,0.8637185072222222,0.9091592383786008,0.910763785,,
160,118,14,Footer,"[(506, 520)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.26194238683127574,0.9340192225,0.9057001553497942,0.9450888058333333,,
161,119,15,Header,"[(0, 1), (1, 6)]","82:16 Pan, Yakhmi, Iyer, et. al.",0.09429629629629631,0.08305529208333332,0.9057092407407409,0.09412487541666666,,
162,120,15,Paragraph,"[(6, 22), (22, 36), (36, 52), (52, 67), (67, 83), (83, 99), (99, 113)]","viewed a paid relationship as a corrupting influence, while others viewed it as source of account- ability. While a large proportion of respondents who labeled the contractor as untrustworthy (39%) and partial (34%) also expressed that the contractor would be subject to platform control, 10% of participants in each case expressed concern that to contractors, moderation would be “just a job.” We anticipated that paid contractors would be perceived as less legitimate due to lack of clarity about their background and lack of faith in their expertise and ability to make nuanced judgments. In free response, however, these types of concerns were expressed by <5% of respondents.",0.0933127572016461,0.11764211833333336,0.909164009976132,0.23110545166666663,,
163,120,15,Paragraph,"[(113, 128), (128, 142), (142, 154), (154, 168), (168, 183), (183, 195), (195, 210), (210, 222), (222, 235), (235, 250), (250, 264), (264, 275)]","By contrast, 25% of respondents made comments like “The least trustworthy would likely be the algorithm due to the complex nature, nuance, and context of the human language. Algorithm[s] cannot navigate the complexities and subtleties of our communications.” 16% expressed awareness that algorithms can be programmed with built-in bias, suggesting that support can depend on specific details of how and why an algorithm is created. Additionally, 32% of respondents made performance based arguments (as rationale or qualification ) about algorithms, markedly higher than for contractors (2%), digital juries (9%), and expert panels (8%). Even many participants who expressed support for algorithmic moderation had reservations. Although nearly one third of respondents believed the algorithm was the most trustworthy process, this support was made conditional at the highest rate of all processes, depending on factors like the algorithm being constructed fairly and impartially (25%) and decisions being subject to checks and balances (11%) and appeal to humans (7%), with similar rates for impartiality .",0.09429629629629631,0.23387267388888897,0.9069233571884774,0.43356840055555557,,
164,120,15,Paragraph,"[(275, 290), (290, 305), (305, 318), (318, 334), (334, 346), (346, 364), (364, 377), (377, 391), (391, 407), (407, 422), (422, 439), (439, 455), (455, 468), (468, 484), (484, 502), (502, 518), (518, 537), (537, 550), (550, 560)]","4.1.3 H1.3. Quantitative and qualitative results definitively refute H1.3 , and both show a strong preference for the expert panel. We anticipated that the greater democratic legitimacy of digital juries and skepticism of claims to expertise in content moderation would override other considerations. While we did find some support for these phenomena in free response, by and large participants viewed expert panels as legitimate, trustworthy, and impartial. Although we anticipated juries’ democratic nature might be seen as a check on the platform’s ability to impose its own standards on the community (a view articulated by few respondents), participants seemed more concerned that digital juries would impose members’ own viewpoints (expressed by 30%) and that vetting would not be rigorous enough (26%). One participant stated, “It would be very difficult for users who liked a person who posts things that violated the standards to be impartial...” Another commented, “they are randomly chosen and could be just about anybody. If there was some type of selection process from Facebook users, then that would be a little bit different.” One participant even fretted about demographic bias in randomly selected juries, saying “Facebook users tend towards certain demographics – the middle aged and not people like me who are younger.” Additionally 8% expressed the idea that regular users are inherently unsuited to the task. Some participants went as far as to reject the legitimacy of juries in the justice system, in one instance, stating, “[The unfairness of juries of users] is similar to how ineffective an actual jury is at trial.” By contrast, 25% of participants showed appreciation for the expert panel members’ training and expertise, suggesting that their perceived greater formal education and experience would help mitigate bias.",0.09197942386831276,0.4513907294444444,0.9088580285111112,0.7641068405555554,,
165,121,15,Section,"(560, 565)",4.2 Importance of Outcome-Preference Alignment,0.09429629629629631,0.7925009005555554,0.5751864884773662,0.806337845,,
166,122,15,Paragraph,"[(565, 579), (579, 597), (597, 609), (609, 623), (623, 640), (640, 646)]","To assess H2 , we consider both qualitative and quantitative factors. Qualitatively, the magnitude of the fixed effect of Alignment, as well as its significance lends support to H2 —that users will report higher perceived legitimacy when content moderation systems make decisions that align with their individual preferences. Since Alignment is on a five-point scale, the maximal variation in perceived legitimacy due to Alignment is approximately 7.4 points out of 20, larger than that of any other variable (see Figure 3).",0.09353909465020577,0.810046285,0.9057122777777777,0.9069040627777778,,
167,123,15,Footer,"[(646, 660)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.09429629629629631,0.9340192225,0.7380540648148148,0.9450888058333333,,
168,124,16,Header,"[(0, 8), (8, 9)]",Comparing The Perceived Legitimacy of Content Moderation Processes 82:17,0.09429629629629631,0.08305529208333332,0.9057049543209879,0.09412487541666666,,
169,125,16,Figure,"[(9, 11)]",Outcome-Preference Alignment,0.35536054290123453,0.4133387155798612,0.5957126951929013,0.42583873120486115,,
170,126,16,Paragraph,"[(11, 16), (16, 20), (20, 26), (26, 31), (31, 35), (35, 40), (40, 43), (43, 44), (44, 45)]",P e r c e i v e d I n s t i t u t i o n a l L e g i t i m a c y 15 20,0.21910076526234568,0.1729715756267363,0.2702799334596397,0.3473592936111112,,
171,127,16,Figure,"[(45, 46), (46, 47)]",-2 -1,0.28523075460193137,0.3923158129878525,0.3960298950497786,0.40112136102451745,,
172,128,16,Paragraph,"[(47, 48), (48, 49), (49, 50)]",0 1 2,0.48106419319276467,0.3923029956149645,0.6821525670933202,0.40112136102451745,,
173,129,16,Figure,"[(50, 52)]",7.4 points,0.7139810697530864,0.25454102289236114,0.772395793294753,0.26454100726736113,,
174,130,16,Caption,"[(52, 69), (69, 86), (86, 90)]",Fig. 3. Shows the approximately 7.4 point range of variation (out of 20) of perceived legitimacy attributable to the linear marginal effect of Alignment. A 95% confidence interval is shown calculated from variance of the fixed effect estimates.,0.09429629629629631,0.44745486,0.9057001481481481,0.49034985999999997,Figure,0.0
175,131,16,Paragraph,"[(90, 104), (104, 117), (117, 131), (131, 144), (144, 161), (161, 178), (178, 189), (189, 193)]","Quantitatively, we find that comparing the model with alternative models with a single variable removed, the largest regression occurs when removing Alignment according to the Akaike infor- mation criterion (AIC), an information theory based measure that balances goodness of fit with model complexity. Performing an ANOVA comparison between the primary model and a model without Alignment, we calculate 𝑝 < . 001. Additionally, we calculate the marginal 𝑅 2 value [105] for a reduced model using Alignment as the sole predictor variable as 0.27, suggesting that 27% of the variance in perceived legitimacy is explainable by outcome-preference alignment, assuming the modeled random effects.",0.09353909465020577,0.5250726738888889,0.9091630498954731,0.6551401738888889,,
176,131,16,Paragraph,"[(193, 206)]",Our model estimates that interactions between Alignment and Process are small and not,0.11479629629629629,0.6579073961111112,0.9057009548148147,0.6717443405555555,,
177,131,16,Paragraph,"[(206, 218), (218, 231), (231, 248), (248, 261), (261, 273)]","statistically significant. Parameter estimates of these interactions are presented in Table 2. In free response, many participants’ explanations for their legitimacy ratings rested solely on their opinion of the moderated post and the random decision shown to them in the study. In addition, when participants were asked to assess the overall trustworthiness and impartiality of moderation processes, a significant proportion made arguments based on the survey examples.",0.09429629629629631,0.6745115627777778,0.9057031842139917,0.7547665627777778,,
178,132,16,Section,"(273, 280)",5 DISCUSSION 5.1 Implications of Process Effects,0.09429629629629631,0.7755495116666667,0.4235335773662551,0.8101420116666668,,
179,133,16,Paragraph,"[(280, 295), (295, 309), (309, 324), (324, 338), (338, 351), (351, 366)]","Our quantitative and qualitative results build a strong case that the Expert Panel is perceived as the most legitimate process by our participants. This result might be considered surprising in light of common criticisms that platforms are undemocratic and biased in favor of unpopular views [77]. The result is especially notable given the limited information participants were given regarding panelist selection, ideological alignment, and the nature and relevance of their expertise. Moreover, our results’ direct refutation of H1.3 seems to show that expertise, rather than the",0.09378395061728395,0.8138504516666667,0.908849234364197,0.913878278611111,,
180,134,16,Footer,"[(366, 380)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.26194238683127574,0.9340192225,0.9057001553497942,0.9450888058333333,,
181,135,17,Header,"[(0, 1), (1, 6)]","82:18 Pan, Yakhmi, Iyer, et. al.",0.09429629629629631,0.08305529208333332,0.9057092407407409,0.09412487541666666,,
182,136,17,Paragraph,"[(6, 18), (18, 35), (35, 51), (51, 66), (66, 84), (84, 89)]","body’s independence from the platform or other characteristics, was what participants appreciated. Perhaps, despite the popular notion of a crisis of mistrust in expertise [42], mistrust of peers is stronger still [90], though different results may be obtained in high trust societies [33] or those whose cultures are poorly represented by the expert body. As one participant noted, “they are experts, they know how to deal with things like this better than anyone. They can be trusted more to make the right decisions.”",0.09353909465020577,0.11764211833333336,0.9088528217201648,0.21450128500000004,,
183,136,17,Paragraph,"[(89, 103), (103, 120), (120, 131), (131, 147), (147, 157)]","With respect to digital juries, other work studying online communities finds similar mistrust of peers and resistance to peer judgment as we observed [44, 85]. Digital juries might offer benefits in certain scenarios, by aligning content moderation enforcement with users’ preferences. However, there remains debate around the ability of digital juries to scale effectively and carry out moderation decisions on platforms that lack diversity like Parler [114, 132].",0.09429629629629631,0.21726850722222224,0.9079551217629627,0.2975235072222222,,
184,136,17,Paragraph,"[(157, 171), (171, 188), (188, 204), (204, 222), (222, 236), (236, 250), (250, 264), (264, 282), (282, 298), (298, 313), (313, 325), (325, 331)]","Recent rulings by the Facebook Oversight Board, in particular its rulings about President Trump’s posts following the 2021 Capitol Riot [6] show that the the exercise of expert authority in content moderation can be fraught in ways that go beyond the process factors examined in this study. Firstly, it is clear that the composition of the body, a variable not manipulated in this study, strongly colors decisions. The board, with heavy representation from lawyers and judges, has couched its reasoning within the framework of judicial review, self-imposing significant limits on the scope of its powers [106]. Secondly, experts may face challenges in claiming and exercising authority, like authority to craft policy, and may be tempted to take a middle of the road approach in controversial cases to safeguard their own perceived legitimacy in the short term [37]. Lastly, while limiting the body’s scope may help avoid controversy, in practice it may push important work like determining how international human rights law applies to content moderation [37], to platform-internal processes with less legitimacy and transparency.",0.09429629629629631,0.3002907294444444,0.9088544616543208,0.496776285,,
185,136,17,Paragraph,"[(331, 344), (344, 355), (355, 370), (370, 385), (385, 401), (401, 417), (417, 431), (431, 446), (446, 459), (459, 475), (475, 489)]","Despite inconclusive results for H1.2 , qualitative analysis does support many phenomena regard- ing algorithmic decision making discussed in prior work—these phenomena suggest widespread belief in algorithmic objectivity but also show several factors limiting trust. The most widely artic- ulated of all attitudes toward moderation processes in the free response was that algorithms don’t apply their own beliefs and agenda to decisions, and the fourth most common was that algorithms make decisions based on logic and rules, not feelings. However, study results show that belief in impartiality does not necessarily translate into a high level of trust or perceived legitimacy—a similar number of respondents gave the algorithm as the least trustworthy process as had given the paid contractor. Prior work notes that positive sentiments toward algorithmic decision making are tempered by factors like the subjectivity of the domain [95, 124], opaqueness of function and deployment [41, 79], and performance [35], elements that can be seen in free response.",0.09429629629629631,0.4995435072222222,0.9091708869497941,0.6794248961111111,,
186,137,17,Section,"(489, 494)",5.2 Implications of Outcome-Preference Alignment,0.09429629629629631,0.6978550672222222,0.5836116502057612,0.7116920116666667,,
187,138,17,Paragraph,"[(494, 505), (505, 517), (517, 531), (531, 545), (545, 548)]","Quantitative results firmly support H2 , showing that outcome-preference alignment strongly determines perceived institutional legitimacy. This influence far outstrips that of the process variables manipulated in this survey. This result arguably poses an intractable problem for platforms, discussed further in Section 5.5, and raises important questions about the perceived legitimacy of majoritarian decision making.",0.09378395061728395,0.7154004516666667,0.9079587813662551,0.7956554516666666,,
188,138,17,Paragraph,"[(548, 560), (560, 574), (574, 587), (587, 602), (602, 615), (615, 629), (629, 633)]","While it is difficult to disentangle outcome-preference alignment and performance in qualitative analysis, outcome favorability bias is a well documented phenomenon in both criminal justice [94] and algorithmic decision making [144]. In contrast to these contexts, however, outcome favorability for bystanders in content moderation is driven less by personal interest and more by beliefs, ideology, and community norms. We can expect, therefore, for personal experience and political discourse to be especially important in shaping presences and the subjective experience of content moderation, as discussed below.",0.09429629629629631,0.7984226738888888,0.9079553677530866,0.9118860072222222,,
189,139,17,Footer,"[(633, 647)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.09429629629629631,0.9340192225,0.7380540648148148,0.9450888058333333,,
190,140,18,Header,"[(0, 8), (8, 9)]",Comparing The Perceived Legitimacy of Content Moderation Processes 82:19,0.09429629629629631,0.08305529208333332,0.9057049543209879,0.09412487541666666,,
191,141,18,Section,"(9, 14)","5.3 Familiarity, Understanding, and Experience",0.09429629629629631,0.1208522894444444,0.5460366588477366,0.13468923388888893,,
192,142,18,Paragraph,"[(14, 28), (28, 44), (44, 59), (59, 62)]","Perceived legitimacy is a sociological phenomenon, and can only be meaningfully studied in the context of a society and the attitudes of individuals therein; however, it naturally follows that levels of perceived legitimacy will vary with the nature of and degree of public awareness, understanding, and idiosyncratic experience.",0.09429629629629631,0.13839767388888902,0.9079488080164607,0.20204850722222226,,
193,142,18,Paragraph,"[(62, 76), (76, 88), (88, 105), (105, 122), (122, 143), (143, 157), (157, 172), (172, 185), (185, 202), (202, 219), (219, 225)]","In comparative free response, five respondents gave a rationale or qualification that they did not understand a process well enough. Some respondents expressed this skepticism forcefully, for example, writing, “...my question is, what are the experts experts in? How do we verify their expertise, and ensure they are operating in an unbiased manner?” and “I do not trust the algorithm because I’m unsure how it was made and what it is looking for in a content in order to determine if it should be removed or not.” However, transparency doesn’t necessarily confer trust [9], especially for algorithmic decision making [24]. As users gain more understanding of the true capabilities of algorithms, they may instead grow more skeptical [32]. Because content moderation today remains opaque to users [60, 116], it is important to ask the question how more knowledge might affect users’ attitudes. By the same token, steps taken by platforms to help build legitimacy can only be effective when users know about them.",0.09429629629629631,0.20481572944444446,0.9079553677530866,0.38469572944444436,,
194,142,18,Paragraph,"[(225, 239), (239, 251), (251, 264), (264, 279), (279, 292), (292, 306), (306, 307)]","Personal experience can also play a major role in shaping attitudes. For algorithmic moderation, as performance improves, positive personal experiences with algorithms would be the likeliest path to changing attitudes. For unfamiliar, emerging content moderation processes, like the digital jury, initial user experiences with the system will be especially important. Although this study did not directly measure or control for familiarity or experience with content moderation mechanisms, future work can explore a single individual’s subjective experience of legitimacy due to personal experience.",0.09429629629629631,0.3874643405555555,0.907962996525103,0.5009276738888889,,
195,143,18,Section,"(307, 310)",5.4 Political Discourse,0.09429629629629631,0.5243397894444445,0.31427296419753087,0.5381767338888889,,
196,144,18,Paragraph,"[(310, 325), (325, 338), (338, 350), (350, 364), (364, 381), (381, 395), (395, 410), (410, 424), (424, 437), (437, 451), (451, 465), (465, 479), (479, 493), (493, 507), (507, 521), (521, 537), (537, 548)]","Despite inconclusive quantitative results on the effect of political affiliation, it is clear that the role of political discourse in shaping attitudes toward content moderation processes cannot be ignored. Anecdotally, multiple participants complained that moderators would be chosen to reflect a political viewpoint, and one participant consistently voiced mistrust of the platform due to its liberal bias. In such cases, political affiliation appeared to play a strong role and some weak patterns emerged—experts were presumed by some users to have liberal bias, and digital juries were presumed to be more tolerant of harmful content. In the United States, content moderation has become a flashpoint, and is viewed by many conservative-leaning individuals as an illegitimate attempt to regulate speech. Rhetoric from partisan opinion leaders, for example the Republican-led FCC’s announcement that it would try to reduce liability protections for platforms that moderate content [4], both reflects and shapes public opinion. Moreover, prior work shows that reactions to hypothetical interventions taken by social media platforms can be heavily influenced by party ideologies [63], and that more generally, liberals and conservatives place a differing degree of importance on components of perceived legitimacy, such as fairness [61]. In this study, qualitative responses show evidence of systemic skepticism on the part of those identifying as conservatives or independents. In any case, the prominence of content moderation as a political issue adds an element of volatility to any attempt to build legitimate moderation systems.",0.09353909465020577,0.5418851738888889,0.9062441784576131,0.8213915627777778,,
197,145,18,Section,"(548, 551)",5.5 Design Implications,0.09429629629629631,0.8448036783333333,0.32690045720164607,0.8586406227777779,,
198,146,18,Paragraph,"[(551, 564), (564, 578), (578, 590)]","Although the strong effect of outcome-preference alignment appears to pose a daunting challenge for platforms, our findings suggest platforms have procedural levers at their disposal to build perceived legitimacy. We outline several such suggestions below, synthesizing our findings with",0.09357818930041152,0.8623490627777778,0.9057084939654324,0.9093957294444445,,
199,147,18,Footer,"[(590, 604)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.26194238683127574,0.9340192225,0.9057001553497942,0.9450888058333333,,
200,148,19,Header,"[(0, 1), (1, 6)]","82:20 Pan, Yakhmi, Iyer, et. al.",0.09429629629629631,0.08305529208333332,0.9057092407407409,0.09412487541666666,,
201,149,19,Paragraph,"[(6, 20), (20, 37), (37, 54), (54, 67), (67, 82), (82, 95)]","analysis of prior work, industry developments, and speculation. However, we note that in general these should be implemented as part of a tiered, hybrid system that not only optimizes for perceived legitimacy but also allows for fast response times in cases where there is a likelihood of immediate harms (e.g., 2019 Christchurch terrorist attack [84]), and accommodates the challenges of scale. Moreover, adopting these measures is only a first step for platforms—indeed, some are already in use. Perceived legitimacy cannot exist without both transparency and public awareness of these",0.09429629629629631,0.11764211833333336,0.9088521059588477,0.21450128500000004,,
202,149,19,Paragraph,"[(95, 110)]","efforts.Because our findings offer clear support for expert panels, we recommend that such bodies be",0.09429629629629631,0.21726850722222224,0.9056984524469137,0.24770961833333335,,
203,149,19,Paragraph,"[(110, 123), (123, 136), (136, 152), (152, 165), (165, 183), (183, 198), (198, 213), (213, 228), (228, 241), (241, 256), (256, 270), (270, 283), (283, 296), (296, 302)]","incorporated into moderation procedures. In practice, however, it would be impractical for such panels to make a large proportion of moderation decisions. Platforms should explore alternative means to incorporate expert judgment into hybrid processes. As a first step, we suggest that a publicly visible and independent expert panel be responsible for drafting moderation guidelines. A next step would be to allow the expert panel to handle appeals of the most controversial cases [78]. By contrast, the Facebook Oversight Board has focused first on deciding borderline cases, and does not have the authority to set policy (though it may recommend policy changes when solicited to do so)[5]. Such an appeals body is especially important when algorithmic moderation is used, given the perceived importance of oversight among study participants. However, expertise can be brought to other places. Digital juries might, for example, include an expert member to facilitate deliberation. More broadly, an independent expert group might be given authority over the overall moderation process. Finally, experts might play a visible role in training rank-and-file moderators, assessing the performance of and appropriate scope for automated systems, and educating the public about the content moderation process.",0.09429629629629631,0.2504768405555555,0.9088594412510288,0.48017211833333334,,
204,149,19,Paragraph,"[(302, 314), (314, 327), (327, 341), (341, 358), (358, 374), (374, 386), (386, 400), (400, 415), (415, 424)]","Because large proportions of our participants displayed wariness of individual moderator biases as well as groupthink in deliberative bodies, we recommend that platforms incorporate multiple perspectives into all processes. While our results might seem to imply majoritarian decision making can be seen as a legitimate in a utilitarian sense, we believe diverse perspectives are even more critical in a divided environment. Platforms should, for example, make clear to users that posts are reviewed by multiple contractors, assuaging our participants’ fears that contractors apply their own biases and opinions to moderation. While Facebook is known to monitor agreement between contractors [107], our results show this is not part of the public consciousness. Deliberative bodies could also employ pre-screening to encourage more diverse composition.",0.09429629629629631,0.48293934055555554,0.9060944524691354,0.6296110072222222,,
205,149,19,Paragraph,"[(424, 438), (438, 450), (450, 463), (463, 477), (477, 489)]","To address concerns about members of digital juries applying personal biases to decisions, we suggest exploring public reputation systems to improve accountability for decisions. Our results suggest that anonymity and lack of vetting hinders accountability. Reputation systems could range from publishing jury deliberation and justifications of decisions to a numerical rating system driven by peer reviews. Similar methods could also improve the accountability of contractors.",0.09429629629629631,0.6323782294444444,0.9057084939654324,0.7126332294444444,,
206,149,19,Paragraph,"[(489, 504), (504, 521), (521, 534), (534, 549), (549, 563), (563, 575), (575, 590), (590, 603)]","We can also look to prior work for solutions to the outcome-preference alignment problem. It is informative to consider prior work on the US Supreme Court, an institution that is forced to make polarizing, politically charged decisions in the public eye. Gibson, for example, suggests legitimacy can arise through a social learning process [53]. It is reasonable, therefore, to conclude that platforms may be able to improve perceived legitimacy over time through sustained public education efforts. Platforms should publish information like how automated systems are constructed and how moderators are selected and trained. Gibson also writes about the negative effects of politicization for perceived legitimacy [21], an outcome platforms should take care to avoid.",0.09429629629629631,0.7154004516666667,0.9057057911522634,0.8454679516666667,,
207,149,19,Paragraph,"[(603, 618), (618, 632), (632, 648), (648, 662)]","We can also look to the literature on procedural justice—there is evidence, for example, that perceptions of legitimacy are enhanced when authorities take extra time to explain how they reached decisions [138], that having the opportunity to express views and opinions, as a user might have during an appeal, can enhance feelings of procedural fairness irrespective of outcome [94],",0.09429629629629631,0.8482351738888888,0.9079578898436214,0.9118860072222222,,
208,150,19,Footer,"[(662, 676)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.09429629629629631,0.9340192225,0.7380540648148148,0.9450888058333333,,
209,151,20,Header,"[(0, 8), (8, 9)]",Comparing The Perceived Legitimacy of Content Moderation Processes 82:21,0.09429629629629631,0.08305529208333332,0.9057049543209879,0.09412487541666666,,
210,152,20,Paragraph,"[(9, 27), (27, 41), (41, 57), (57, 62)]","and that mere knowledge of such a right can have beneficial effects even if not availed [138]. An analogous phenomenon has also been described in the context of online content moderation [74], and it is likely that enhancing the quantity and quality of communication between the user and platform can improve perceived legitimacy.",0.09429629629629631,0.11764211833333336,0.9079572885333332,0.18129295166666662,,
211,153,20,Section,"(62, 64)",5.6 Limitations,0.09429629629629631,0.1997231227777778,0.2480196242798354,0.21356006722222232,,
212,154,20,Paragraph,"[(64, 77), (77, 91), (91, 103), (103, 119), (119, 132), (132, 146), (146, 161), (161, 176), (176, 190), (190, 206), (206, 221), (221, 225)]","While this study provides a novel comparative perspective on content moderation processes, the study design has several limitations. First, the study attempts to measure and analyze prevailing public attitudes toward content moderation processes. However, we recognize that the formation of attitudes is a multi-faceted social and experiential process, and our study design does not allow rigorous claims about attitude formation. Furthermore, our study measures attitudes at a single snapshot in time—we did not provide an opportunity for participants to gain experience with each process, instead exposing participants to a single decision per process. In addition, the study focused on highly disagreed-upon posts, and results may not generalize to all types of moderated content. Additionally, since the study only investigated one possible version of each process type, results may not generalize to all possible versions of these processes. A future study could not only examine more versions of these processes, but also identify which attributes (e.g., jury rules) contribute to perceived legitimacy.",0.0933127572016461,0.21726850722222224,0.9079611895193418,0.4137540627777777,,
213,154,20,Paragraph,"[(225, 240), (240, 256), (256, 270), (270, 285), (285, 299), (299, 303)]","Since our study was scoped to only include industrial content moderation, we did not investigate moderation and artisanal moderation, which gives rise to two limitations. The first is that we know less about the perceived legitimacy of the excluded approaches. Second, this work only investigates how moderation processes impact the perceived legitimacy of rule enforcement , not rule creation . Thus, the results may not generalize well to the perceived legitimacy of moderation processes involved in rule creation.",0.09368106995884774,0.416521285,0.9088594438683127,0.5133804516666666,,
214,154,20,Paragraph,"[(303, 318), (318, 333), (333, 344), (344, 355), (355, 370), (370, 384), (384, 398), (398, 412), (412, 426), (426, 441), (441, 457), (457, 459)]","Biases in our user population may also limit generalizability of results. While the study was conducted among Facebook users, the demographics of AMT workers do not exactly match that of Facebook’s US user base. The survey population overrepresented higher-educated and non-Hispanic white individuals and underrepresented multiple minority groups. Furthermore, the technical and digital nature of AMT work may mean that our survey respondents had a different relationship with online platforms than average social media users. Additionally, our study was limited to one social media platform (Facebook) in one country (United States). In addition, since attitudes and perceptions vary upon their existing knowledge of content moderation, the results may not generalize to populations with highly expert populations. A future cross cultural study may be needed to determine which drivers of perceived legitimacy are more universal and which are more specific to the United States, its present cultural moment, and the present level of knowledge about content moderation.",0.09353909465020577,0.5161476738888889,0.9057062011358025,0.7126332294444444,,
215,154,20,Paragraph,"[(459, 472), (472, 486), (486, 498), (498, 510), (510, 523), (523, 524)]","Additionally, two potentially significant factors of moderation processes we do not consider in this work are when moderation is carried out (i.e., pre-moderation vs. post-moderation) [29, 142], and tiered or hybrid moderation processes. Qualitative results suggest knowledge of oversight mechanisms and appeals processes can influence perception of legitimacy, and holistic assessment of perceived legitimacy of governance mechanisms in practice requires consideration of the entire system.",0.09429629629629631,0.7154004516666667,0.9079588079934157,0.8122596183333334,,
216,155,20,Section,"(524, 527)",5.7 Future Work,0.09429629629629631,0.8306911783333334,0.2596631567901235,0.8445281227777778,,
217,156,20,Paragraph,"[(527, 541), (541, 554), (554, 566), (566, 579)]","Future studies should more rigorously examine tiered processes, the impact of oversight, and the appeals process. Our qualitative results indicate that including these processes may be especially significant for algorithmic moderation, where participants indicated a desire for human oversight. Additionally, future work should examine how the wide array of artisanal and community-driven",0.09357818930041152,0.8482351738888888,0.9088492958617284,0.9118860072222222,,
218,157,20,Footer,"[(579, 593)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.26194238683127574,0.9340192225,0.9057001553497942,0.9450888058333333,,
219,158,21,Header,"[(0, 1), (1, 6)]","82:22 Pan, Yakhmi, Iyer, et. al.",0.09429629629629631,0.08305529208333332,0.9057092407407409,0.09412487541666666,,
220,159,21,Paragraph,"[(6, 19), (19, 33), (33, 45), (45, 60), (60, 66)]","moderation models found in platforms like Reddit, Vimeo, Patreon, Wikipedia, and League of Legends affect perceived legitimacy when employed together with or in place of industrial content moderation processes. Given that these approaches tend to have more community participation in governance, future work comparing them needs to be careful to separate the investigation of moderation legitimacy from that of governance.",0.09429629629629631,0.11764211833333336,0.9057040661432098,0.19789711833333332,,
221,159,21,Paragraph,"[(66, 81), (81, 94), (94, 108), (108, 123), (123, 137), (137, 150), (150, 158)]","A second area for future work is to investigate how hybrid moderation processes can better incorporate expertise. While we can hypothesize the benefit of expertise for perceived legitimacy will diminish the further removed experts are from day-to-day decision making, hybrid models are the only practical solution to scaling challenges. A promising direction might be to combine elements of the expert panel and digital jury—for example, including an expert facilitator or introducing credentialing for jury members. Additionally, future work should examine the importance of specific types of expertise and representation of diverse viewpoints.",0.09353909465020577,0.20066434055555568,0.9062349128296293,0.31412767388888885,,
222,159,21,Paragraph,"[(158, 174), (174, 185), (185, 200), (200, 216), (216, 229), (229, 244), (244, 258), (258, 270), (270, 284), (284, 297), (297, 309)]","A third critical area is to investigate the impact of political affiliation and political debate on perceived legitimacy. While quantitative and qualitative results hinted that conservatives and independents may be less trusting of content moderation processes in general, the power of the study was not sufficient to establish this. Future studies can not only investigate this effect, but also examine the interaction of political affiliation with elements of moderation process design. Moreover, while this study did establish the importance of normative preferences, it did not attempt to distinguish political or closely held preferences from other preferences, and did not specifically distinguish content with a significant political dimension from content without this dimension. An especially important topic for future work is studying how sticky factors like institutional commitment and decisional jurisdiction are in the face of politically unpalatable decisions, and what role normative concepts like democratic legitimacy play in politically charged environments.",0.09353909465020577,0.3168948961111111,0.9088656511572017,0.496776285,,
223,160,21,Section,"(309, 311)",6 CONCLUSION,0.09429629629629631,0.5262759005555555,0.26236904814814815,0.540112845,,
224,161,21,Paragraph,"[(311, 323), (323, 337), (337, 352), (352, 370), (370, 384), (384, 397), (397, 409), (409, 425)]","As online platforms and their governance mechanisms increasingly resemble digital polities, plat- forms must focus greater attention on user perceptions of legitimacy. However creating a legitimate content moderation process appears to be a nearly intractable problem as long as people with different views continue to occupy the same digital spaces. Not only is the scale of the task daunting, but this study also highlights the degree to which individual outcome preferences can dominate perceptions of legitimacy, regardless of how platforms design their processes. Content for which opinions differ wildly, therefore, poses a “catch-22” to platforms—goodwill generated with one segment of the user population may be met in equal measure with feelings of illegitimacy by",0.09357818930041152,0.543821285,0.909163937400823,0.6738901738888889,,
225,161,21,Paragraph,"[(425, 436)]","another.Nevertheless, our quantitative and qualitative results illuminate potential paths forward. We",0.09429629629629631,0.6766573961111111,0.9057062011358022,0.7070985072222222,,
226,161,21,Paragraph,"[(436, 451), (451, 464), (464, 476), (476, 489), (489, 504), (504, 517), (517, 530), (530, 533)]","find the strongest support for a robust role for experts in content moderation processes, with participants perceiving the expert panel as having high levels of trustworthiness, fairness and impartiality, and overall perceived institutional legitimacy. Our qualitative results also indicate a preference among users for group decision making over decisions made by individuals, supporting future work on processes that synthesize multiple views. Our results are also consistent with prior work on attitudes toward algorithmic decision making, showing that while algorithms can be perceived as legitimate decision makers, their performance and users’ experience with them will significantly shape attitudes.",0.09353909465020577,0.7098657294444444,0.9060858428148147,0.8399332294444444,,
227,161,21,Paragraph,"[(533, 546), (546, 557), (557, 574), (574, 588)]","Today, content moderation stands at an inflection point. While platforms are accountable for their content moderation practices, academics and policymakers are increasingly vocal participants in shaping the future of content moderation, and the public will have the final say. Criticism of existing mechanisms abounds, but so do proposals and experiments seeking to build better systems.",0.09429629629629631,0.8427004516666667,0.9088528217201648,0.906351285,,
228,162,21,Footer,"[(588, 602)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.09429629629629631,0.9340192225,0.7380540648148148,0.9450888058333333,,
229,163,22,Header,"[(0, 8), (8, 9)]",Comparing The Perceived Legitimacy of Content Moderation Processes 82:23,0.09429629629629631,0.08305529208333332,0.9057049543209879,0.09412487541666666,,
230,164,22,Paragraph,"[(9, 26), (26, 32)]",Studies of perceived legitimacy can be a powerful tool for all groups to ensure these systems are trusted and respected by the public.,0.09429629629629631,0.11764211833333336,0.9056926686008229,0.14808322944444446,,
231,165,22,Section,"(32, 33)",ACKNOWLEDGMENTS,0.09429629629629631,0.16651478944444448,0.3159948950617284,0.18035173388888903,,
232,166,22,Paragraph,"[(33, 48), (48, 62), (62, 78), (78, 80)]",We thank the reviewers for their helpful comments and suggestions. We also thank Michael Sklar of the Stanford Department of Statistics for statistical advice. The Stanford Computer Science (CS) department provided funds to assist this research. This project was supported by the Office of Naval Research (N00014-21-1-2839).,0.0933127572016461,0.18406017388888896,0.9069264525641972,0.24770961833333335,,
233,167,22,Footer,"[(80, 94)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.26194238683127574,0.9340192225,0.9057001553497942,0.9450888058333333,,
234,168,23,Header,"[(0, 1), (1, 6)]","82:24 Pan, Yakhmi, Iyer, et. al.",0.09429629629629631,0.08305529208333332,0.9057092407407409,0.09412487541666666,,
235,169,23,Section,"(6, 7)",REFERENCES,0.09429629629629636,0.1208522894444444,0.22344111111111117,0.13468923388888893,,
236,170,23,Bibliography,"[(7, 23), (23, 40), (40, 61), (61, 65), (65, 88), (88, 112), (112, 127), (127, 152), (152, 171), (171, 183), (183, 215), (215, 229), (229, 246), (246, 281), (281, 300), (300, 338), (338, 359), (359, 381), (381, 399), (399, 411), (411, 430), (430, 448), (448, 461), (461, 482), (482, 495), (495, 522), (522, 543), (543, 565)]","[1] [n.d.]. The Plain View Project . https://www.plainviewproject.org/ [2] 2018. The Santa Clara Principles . https://santaclaraprinciples.org/ [3] 2019. Facebook Community Standards . https://transparency.fb.com/policies/community-standards/ [4] 2020. Chairman Pai Statement on Section 230 . https://www.fcc.gov/document/chairman-pai-statement-section-230 [5] 2020. Oversight Board . https://oversightboard.com/ [6] 2021. Oversight Board upholds former President Trump’s suspension, finds Facebook failed to impose proper penalty . https://oversightboard.com/news/226612455899839-oversight-board-upholds-former-president-trump-s- suspension-finds-facebook-failed-to-impose-proper-penalty/ [7] 2021. Parler Community Jury . https://legal.parler.com/documents/Parler-Community-Jury.pdf [8] Amina Adadi and Mohammed Berrada. 2018. Peeking inside the black-box: A survey on Explainable Artificial Intelligence (XAI). IEEE Access 6 (2018), 52138–52160. [9] Mike Ananny and Kate Crawford. 2018. Seeing without knowing: Limitations of the transparency ideal and its application to algorithmic accountability. New Media & Society 20, 3 (2018), 973–989. https://doi.org/10.1177/ 1461444816676645 arXiv:https://doi.org/10.1177/1461444816676645 [10] Julia Angwin, ProPublica, and Hannes Grassegger. 2017. Facebook’s Secret Censorship Rules Protect White Men From Hate Speech But Not Black Children. ProPublica (2017). https://www.propublica.org/article/facebook-hate- speech-censorship-internal-documents-algorithms [11] Theo Araujo, Natali Helberger, Sanne Kruikemeier, and Claes de Vreese. 2020. In AI we trust? Perceptions about automated decision-making by artificial intelligence. AI & SOCIETY (01 2020). https://doi.org/10.1007/s00146-019- 00931-w [12] Jack M Balkin. 2015. Information fiduciaries and the first amendment. UCDL Rev. 49 (2015), 1183. [13] Chelsea Barabas, Karthik Dinakar, Joichi Ito, Madars Virza, and Jonathan Zittrain. 2017. Interventions over Predictions: Reframing the Ethical Debate for Actuarial Risk Assessment. CoRR abs/1712.08238 (2017). arXiv:1712.08238 http: //arxiv.org/abs/1712.08238 [14] Solon Barocas, Moritz Hardt, and Arvind Narayanan. 2019. Fairness and Machine Learning . fairmlbook.org. http: //www.fairmlbook.org. [15] Solon Barocas and Andrew D Selbst. 2016. Big data’s disparate impact. Calif. L. Rev. 104 (2016), 671. [16] David Beer. 2017. The social power of algorithms. Information, Communication & Society 20, 1 (2017), 1–13. https://doi.org/10.1080/1369118X.2016.1216147 arXiv:https://doi.org/10.1080/1369118X.2016.1216147 [17] Maria Ines Bergoglio. 2017. Ten Years of Mixed Tribunals in Argentina. Available at SSRN 2987942 (2017). [18] Reuben Binns, Max Van Kleek, Michael Veale, Ulrik Lyngs, Jun Zhao, and Nigel Shadbolt. 2018. ’It’s Reducing a Human Being to a Percentage’: Perceptions of Justice in Algorithmic Decisions. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (Montreal QC, Canada) (CHI ’18) . Association for Computing Machinery, New York, NY, USA, 1–14. https://doi.org/10.1145/3173574.3173951 [19] Gerd Bohner and Nina Dickel. 2011. Attitudes and Attitude Change. Annual Review of Psychology 62, 1 (2011), 391– 417. https://doi.org/10.1146/annurev.psych.121208.131609 arXiv:https://doi.org/10.1146/annurev.psych.121208.131609 PMID: 20809791. [20] Marc Bühlmann and Ruth Kunz. 2011. Confidence in the Judiciary: Comparing the Independence and Legitimacy of Judicial Systems. West European Politics 34, 2 (2011), 317–345. https://doi.org/10.1080/01402382.2011.546576 arXiv:https://doi.org/10.1080/01402382.2011.546576 [21] Gregory A. Caldeira and James L. Gibson. 1992. The Etiology of Public Support for the Supreme Court. American Journal of Political Science 36, 3 (1992), 635–664. http://www.jstor.org/stable/2111585 [22] Robyn Caplan. 2018. Content or context moderation? (2018). [23] Claude Castelluccia and Daniel Le Métayer. 2019. Understanding algorithmic decision-making: Opportunities and challenges . European Parliament. [24] Hao-Fei Cheng, Ruotong Wang, Zheng Zhang, Fiona O’Connell, Terrance Gray, F. Maxwell Harper, and Haiyi Zhu. 2019. Explaining Decision-Making Algorithms through UI: Strategies to Help Non-Expert Stakeholders. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (Glasgow, Scotland Uk) (CHI ’19) . Association for Computing Machinery, New York, NY, USA, 1–12. https://doi.org/10.1145/3290605.3300789 [25] Paolo Chiocchetti. 2017. Democratic Legitimacy . https://resume.uni.lu/story/democratic-legitimacy [26] Danielle Keats Citron. 2009. Cyber civil rights. BUL Rev. 89 (2009), 61. [27] J. Clement. 2020. Distribution of Facebook users in the United States as of August 2020, by age group . https://www. statista.com/statistics/187549/facebook-distribution-of-users-age-group-usa/",0.10192181069958835,0.13839283361111115,0.9082345660576131,0.8689860280555556,,
237,171,23,Footer,"[(565, 580), (580, 594)]","[28] J. Clement. 2020. Facebook: number of monthly active users worldwide 2008-2020 . https://statista.com/statistics/264810/ number-of-monthly-active-facebook-users-worldwide/ Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.09429629629629628,0.8717525558333333,0.9067725860164609,0.9450888058333333,,
238,172,24,Header,"[(0, 8), (8, 9)]",Comparing The Perceived Legitimacy of Content Moderation Processes 82:25,0.09429629629629631,0.08305529208333332,0.9057049543209879,0.09412487541666666,,
239,173,24,Bibliography,"[(9, 23), (23, 38), (38, 65), (65, 89), (89, 113), (113, 139), (139, 152), (152, 182), (182, 199), (199, 221), (221, 238), (238, 256), (256, 294), (294, 316), (316, 349), (349, 371), (371, 379), (379, 381), (381, 399), (399, 433), (433, 452), (452, 488), (488, 518), (518, 537), (537, 543), (543, 561), (561, 587), (587, 602), (602, 627), (627, 646), (646, 673), (673, 702), (702, 707)]","[29] Cambridge Consultants. 2019. Use of AI in Online Content Moderation . https://www.ofcom.org.uk/__data/assets/pdf_ file/0028/157249/cambridge-consultants-ai-content-moderation.pdf [30] Alexander Coppock. 2019. Generalizing from survey experiments conducted on Mechanical Turk: A replication approach. Political Science Research and Methods 7, 3 (2019), 613–628. [31] Kate Crawford. 2017. The trouble with bias. In Conference on Neural Information Processing Systems, invited speaker . [32] Jenny de Fine Licht. 2011. Do we really want to know? The potentially negative effect of transparency in decision making on perceived legitimacy. Scandinavian Political Studies 34, 3 (2011), 183–201. [33] Jan Delhey and Kenneth Newton. 2005. Predicting Cross-National Levels of Social Trust: Global Pattern or Nordic Exceptionalism? European Sociological Review 21, 4 (2005), 311–327. http://www.jstor.org/stable/4621213 [34] L. DeNardis and A.M. Hackl. 2015. Internet governance by social media platforms. Telecommunications Policy 39, 9 (2015), 761 – 770. https://doi.org/10.1016/j.telpol.2015.04.003 SPECIAL ISSUE ON THE GOVERNANCE OF SOCIAL MEDIA. [35] Berkeley J Dietvorst, Joseph P Simmons, and Cade Massey. 2015. Algorithm aversion: People erroneously avoid algorithms after seeing them err. Journal of Experimental Psychology: General 144, 1 (2015), 114. [36] Evelyn Douek. 2019. Verified Accountability: Self-Regulation of Content Moderation as an Answer to the Special Problems of Speech Regulation . https://www.hoover.org/research/verified-accountability [37] Evelyn Douek. 2021. It’s Not Over. The Oversight Board’s Trump Decision Is Just the Start. https://www.lawfareblog. com/its-not-over-oversight-boards-trump-decision-just-start [38] James N Druckman and Toby Bolsen. 2011. Framing, motivated reasoning, and opinions about emergent technologies. Journal of Communication 61, 4 (2011), 659–688. [39] David Easton. 1965. A systems analysis of political life. (1965). [40] Motahhare Eslami, Karrie Karahalios, Christian Sandvig, Kristen Vaccaro, Aimee Rickman, Kevin Hamilton, and Alex Kirlik. 2016. First I ""like"" It, Then I Hide It: Folk Theories of Social Feeds. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (San Jose, California, USA) (CHI ’16) . Association for Computing Machinery, New York, NY, USA, 2371–2382. https://doi.org/10.1145/2858036.2858494 [41] Motahhare Eslami, Kristen Vaccaro, Min Kyung Lee, Amit Elazari Bar On, Eric Gilbert, and Karrie Karahalios. 2019. User Attitudes towards Algorithmic Opacity and Transparency in Online Reviewing Platforms (CHI ’19) . Association for Computing Machinery, New York, NY, USA, 1–14. https://doi.org/10.1145/3290605.3300724 [42] Gil Eyal. 2019. The crisis of expertise . John Wiley & Sons. [43] Facebook. [n.d.]. Facebook’s Third-Party Fact-Checking Program. ([n.d.]). https://www.facebook.com/ journalismproject/programs/third-party-fact-checking [44] Jenny Fan and Amy X Zhang. 2020. Digital Juries: A Civics-Oriented Approach to Platform Governance. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems . 1–14. [45] Victoria A Farrar-Myers and Jason B Myers. 2001. Echoes of the Founding: The Jury in Civil Cases as Conferrer of Legitimacy. SMUL Rev. 54 (2001), 1857. [46] Michel Foucault. 1980. Power/knowledge: Selected interviews and other writings, 1972-1977 . Vintage. [47] John French and Bertram Raven. 1959. The bases of social power . Vol. 6. [48] Seth Frey, P. M. Krafft, and Brian C. Keegan. 2019. ""This Place Does What It Was Built For"": Designing Digital Institutions for Participatory Change. 3, CSCW, Article 32 (Nov. 2019), 31 pages. https://doi.org/10.1145/3359134 [49] Archon Fung. 2013. Infotopia Unleashing the Democratic Power of Transparency. Politics & Society 41 (06 2013), 183–212. https://doi.org/10.1177/0032329213483107 [50] Cary Funk, Meg Hefferon, Brian Kennedy, and Courtney Johnson. 2019. Trust and Mistrust in Americans’ Views of Scientific Experts . https://www.pewresearch.org/science/2019/08/02/trust-and-mistrust-in-americans-views-of- scientific-experts/ [51] James Gibson, Gregory Caldeira, and Vanessa Baird. 1998. On the Legitimacy of National High Courts. The American Political Science Review 92 (06 1998), 343. https://doi.org/10.2307/2585668 [52] James Gibson and Michael Nelson. 2014. The Legitimacy of the US Supreme Court: Conventional Wisdoms and Recent Challenges Thereto. Annual Review of Law and Social Science 10 (11 2014), 201–219. https://doi.org/10.1146/annurev- lawsocsci-110413-030546 [53] James L Gibson. 2007. The legitimacy of the US Supreme Court in a polarized polity. Journal of empirical legal studies 4, 3 (2007), 507–538. [54] James L. Gibson. 2008. Challenges to the Impartiality of State Supreme Courts: Legitimacy Theory and ""New-Style"" Judicial Campaigns. The American Political Science Review 102, 1 (2008), 59–75. http://www.jstor.org/stable/27644498 [55] James L Gibson and Gregory A Caldeira. 2003. Defenders of democracy? Legitimacy, popular acceptance, and the South African Constitutional Court. The Journal of Politics 65, 1 (2003), 1–30. [56] Tarleton Gillespie. 2018. Custodians of the internet: Platforms, content moderation, and the hidden decisions that shape social media . 1–288 pages.",0.1019218106995884,0.12040394472222225,0.908235274753086,0.9089138936111111,,
240,174,24,Footer,"[(707, 721)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.2619423868312757,0.9340192225,0.9057001553497942,0.9450888058333333,,
241,175,25,Header,"[(0, 1)]",82:26,0.09429629629629631,0.08305529208333332,0.12840701234567903,0.09412487541666666,,
242,176,25,Bibliography,"[(1, 6), (6, 34), (34, 61), (61, 77), (77, 95), (95, 115), (115, 140), (140, 174), (174, 203), (203, 225), (225, 246), (246, 263), (263, 287), (287, 303), (303, 322), (322, 341), (341, 373), (373, 391), (391, 411), (411, 440), (440, 457), (457, 472), (472, 506), (506, 526), (526, 543), (543, 560), (560, 570), (570, 599), (599, 604), (604, 628), (628, 657)]","Pan, Yakhmi, Iyer, et. al. [57] Tarleton Gillespie and P. Boczkowski. 2013. The Relevance of Algorithms. [58] Paul Goren, Christopher M Federico, and Miki Caul Kittilson. 2009. Source cues, partisan identities, and political value expression. American Journal of Political Science 53, 4 (2009), 805–820. [59] Robert Gorwa. 2019. What is platform governance? Information, Communication & Society 22, 6 (2019), 854–871. https://doi.org/10.1080/1369118X.2019.1573914 arXiv:https://doi.org/10.1080/1369118X.2019.1573914 [60] Robert Gorwa, Reuben Binns, and Christian Katzenbach. 2020. Algorithmic content moderation: Technical and political challenges in the automation of platform governance. Big Data & Society 7, 1 (2020), 2053951719897945. https://doi.org/10.1177/2053951719897945 arXiv:https://doi.org/10.1177/2053951719897945 [61] Jesse Graham, Jonathan Haidt, and Brian A Nosek. 2009. Liberals and conservatives rely on different sets of moral foundations. Journal of personality and social psychology 96, 5 (2009), 1029. [62] James Grimmelmann. 2015. The virtues of moderation. Yale JL & Tech. 17 (2015), 42. [63] Kirsikka Grön and Matti Nelimarkka. 2020. Party Politics, Values and the Design of Social Media Services: Implications of Political Elites’ Values and Ideologies to Mitigating of Political Polarisation through Design. Proc. ACM Hum.- Comput. Interact. 4, CSCW2, Article 104 (Oct. 2020), 29 pages. https://doi.org/10.1145/3415175 [64] Jürgen Habermas, Thomas McCarthy, and Thomas McCarthy. 1984. The theory of communicative action . Vol. 1. SciELO Brasil. [65] Valerie P Hans and Jonathan D Casper. 2019. Trial by Jury, the Legitimacy of the Courts, and Crime Control. The Crime Conundrum (2019), 93–106. [66] Kotaro Hara, Abigail Adams, Kristy Milland, Saiph Savage, Chris Callison-Burch, and Jeffrey P Bigham. 2018. A data-driven analysis of workers’ earnings on Amazon Mechanical Turk. In Proceedings of the 2018 CHI conference on human factors in computing systems . 1–14. [67] Tad Hirsch, Kritzia Merced, Shrikanth Narayanan, Zac E Imel, and David C Atkins. 2017. Designing contestability: Interaction design, machine learning, and mental health. In Proceedings of the 2017 Conference on Designing Interactive Systems . 95–99. [68] Christopher Hood and David Heald. 2012. Transparency The Key to Better Governance? 1–246 pages. https: //doi.org/10.5871/bacad/9780197263839.001.0001 [69] Youyang Hou, Cliff Lampe, Maximilian Bulinski, and J.J. Prescott. 2017. Factors in Fairness and Emotion in Online Case Resolution Systems. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (Denver, Colorado, USA) (CHI ’17) . Association for Computing Machinery, New York, NY, USA, 2511–2522. https://doi.org/10. 1145/3025453.3025968 [70] Pauline Houlden, Stephen LaTour, Laurens Walker, and John Thibaut. 1978. Preference for modes of dispute resolution as a function of process and decision control. Journal of Experimental Social Psychology 14, 1 (1978), 13 – 30. https://doi.org/10.1016/0022-1031(78)90057-4 [71] Ben Hutchinson and Margaret Mitchell. 2019. 50 Years of Test (Un)Fairness: Lessons for Machine Learning (FAT* ’19) . Association for Computing Machinery, New York, NY, USA, 49–58. https://doi.org/10.1145/3287560.3287600 [72] Jonathan Jackson, Jenna Milani, and Ben Bradford. 2018. Empirical legitimacy and normative compliance with the law. Global encyclopedia of public administration, public policy, and governance. Advance online publication. https://doi. org/10.1007/978-3-319-31816-5_1914-1 (2018). [73] Shagun Jhaver, Darren Scott Appling, Eric Gilbert, and Amy Bruckman. 2019. ""Did You Suspect the Post Would Be Removed?"": Understanding User Reactions to Content Removals on Reddit. 3, CSCW, Article 192 (Nov. 2019), 33 pages. https://doi.org/10.1145/3359294 [74] Shagun Jhaver, Amy Bruckman, and Eric Gilbert. 2019. Does transparency in moderation really matter? user behavior after content removal explanations on reddit. Proceedings of the ACM on Human-Computer Interaction 3, CSCW (2019), 1–27. [75] David Jurgens, Libby Hemphill, and Eshwar Chandrasekharan. 2019. A Just and Comprehensive Strategy for Using NLPtoAddressOnlineAbuse.In Proceedingsofthe57thAnnualMeetingoftheAssociationforComputationalLinguistics . Association for Computational Linguistics, Florence, Italy, 3658–3666. https://doi.org/10.18653/v1/P19-1357 [76] David Kaye. 2018. A human rights approach to platform content regulation. [77] David Kaye. 2019. Speech police: The global struggle to govern The Internet . Columbia Global Reports. [78] DavidKaye,AmosToh,EileenDonahoe,LarryDiamond,MeganMetzger,JanRydzak,RoyaPakzad,SarahiZaldumbide,ThomasHughes,BarboraBukovská,PierreFrançoisDocquir,andBarbaraDockalova.2019. Social Media Councils: From Concept To Reality . https://fsi.stanford.edu/content/social-media-councils-concept-reality-conference-report [79] René F. Kizilcec. 2016. How Much Information? Effects of Transparency on Trust in an Algorithmic Interface. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (San Jose, California, USA) (CHI ’16) . Association for Computing Machinery, New York, NY, USA, 2390–2395. https://doi.org/10.1145/2858036.2858402",0.1019218106995884,0.08305529208333332,0.9082349935432098,0.8786721391666666,,
243,177,25,Footer,"[(657, 668), (668, 682)]","[80] Joseph T Klapper. 1960. The effects of mass communication. (1960). Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.09429629629629628,0.8814386669444444,0.7380540648148148,0.9450888058333333,,
244,178,26,Header,"[(0, 8), (8, 9)]",Comparing The Perceived Legitimacy of Content Moderation Processes 82:27,0.09429629629629631,0.08305529208333332,0.9057049543209879,0.09412487541666666,,
245,179,26,Bibliography,"[(9, 30), (30, 66), (66, 85), (85, 89), (89, 119), (119, 141), (141, 166), (166, 189), (189, 217), (217, 237), (237, 249), (249, 259), (259, 278), (278, 293), (293, 312), (312, 349), (349, 362), (362, 395), (395, 414), (414, 433), (433, 451), (451, 473), (473, 488), (488, 516), (516, 530), (530, 554), (554, 573), (573, 585), (585, 608)]","[81] Joshua Klayman. 1995. Varieties of Confirmation Bias. Psychology of Learning and Motivation, Vol. 32. Academic Press, 385 – 418. https://doi.org/10.1016/S0079-7421(08)60315-1 [82] Kenneth S Klein. 2016. Truth and Legitimacy (in Courts). Loy. U. Chi. LJ 48 (2016), 1. [83] Kate Klonick. 2017. The new governors: The people, rules, and processes governing online speech. Harv. L. Rev. 131 (2017), 1598. [84] Kate Klonick. 2019. Inside the Team at Facebook that Dealt with the Christchurch Shooting. The New Yorker (2019). https://www.newyorker.com/news/news-desk/inside-the-team-at-facebook-that-dealt-with-the- christchurch-shooting [85] Yubo Kou, Xinning Gui, Shaozeng Zhang, and Bonnie Nardi. 2017. Managing Disruptive Behavior through Non- Hierarchical Governance: Crowdsourcing in League of Legends and Weibo. Proc. ACM Hum.-Comput. Interact. 1, CSCW, Article 62 (Dec. 2017), 17 pages. https://doi.org/10.1145/3134697 [86] Anton Kühberger, Michael Schulte-Mecklenbeck, and Josef Perner. 2002. Framing decisions: Hypothetical and real. Organizational Behavior and Human Decision Processes 89, 2 (2002), 1162–1175. [87] Ziva Kunda. 1990. The case for motivated reasoning. Psychological bulletin 108, 3 (1990), 480. [88] Daniel B. le Roux and Douglas A. Parry. 2020. The Town Square in Your Pocket: Exploring Four Metaphors of Social Media. In Responsible Design, Implementation and Use of Information and Communication Technology , Marié Hattingh, Machdel Matthee, Hanlie Smuts, Ilias Pappas, Yogesh K. Dwivedi, and Matti Mäntymäki (Eds.). Springer International Publishing, Cham, 187–198. [89] Min Kyung Lee. 2018. Understanding perception of algorithmic decisions: Fairness, trust, and emotion in response to algorithmic management. Big Data & Society 5, 1 (2018), 2053951718756684. https://doi.org/10.1177/2053951718756684 arXiv:https://doi.org/10.1177/2053951718756684 [90] Scott Keeter Lee Rainie and Andrew Perrin. 2019. https://www.pewresearch.org/politics/2019/07/22/trust-and-distrust- in-america/ . https://www.pewresearch.org/politics/2019/07/22/trust-and-distrust-in-america/ [91] Thomas J Leeper and Rune Slothuus. 2014. Political parties, motivated reasoning, and public opinion formation. Political Psychology 35 (2014), 129–156. [92] Théophile Lenoir. 2020. Challenges of Content Moderation . https://www.institutmontaigne.org/en/blog/challenges- content-moderation [93] Alain A. Levasseur. 2002. Legitimacy of Judges. The American Journal of Comparative Law 50 (2002), 43–85. http://www.jstor.org/stable/840871 [94] E Allan Lind and Tom R Tyler. 1988. The social psychology of procedural justice . Springer Science & Business Media. [95] Jennifer Logg, Julia Minson, and Don Moore. 2019. Algorithm appreciation: People prefer algorithmic to human judgment. Organizational Behavior and Human Decision Processes 151 (03 2019), 90–103. https://doi.org/10.1016/j. obhdp.2018.12.005 [96] Charles Lord, Lee Ross, and Mark Lepper. 1979. Biased Assimilation and Attitude Polarization: The Effects of Prior Theories on Subsequently Considered Evidence. Journal of Personality and Social Psychology 37 (11 1979), 2098–2109. https://doi.org/10.1037/0022-3514.37.11.2098 [97] Steven G Luke. 2017. Evaluating significance in linear mixed-effects models in R. Behavior research methods 49, 4 (2017), 1494–1502. [98] Alan Lundgard. 2020. Measuring Justice in Machine Learning. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (Barcelona, Spain) (FAT* ’20) . Association for Computing Machinery, New York, NY, USA, 680. https://doi.org/10.1145/3351095.3372838 [99] Stefan Machura. 2003. Fairness, justice, and legitimacy: Experiences of people’s judges in South Russia. Law & Policy 25, 2 (2003), 123–150. [100] J. Nathan Matias and Merry Mou. 2018. CivilServant: Community-Led Experiments in Platform Governance. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (Montreal QC, Canada) (CHI ’18) . Association for Computing Machinery, New York, NY, USA, 1–13. https://doi.org/10.1145/3173574.3173583 [101] TJ McIntyre and Colin Scott. 2008. Internet Filtering: Rhetoric, Legitimacy, Accountability. Regulating technologies: Legal futures, regulatory frames and technological fixes (2008), 109. [102] Chris Meserole. 2020. Zuckerberg’s dilemma: How to moderate Facebook amid violent unrest . https://www.brookings. edu/techstream/zuckerbergs-dilemma-how-to-moderate-facebook-amid-violent-unrest/ [103] Brent Mittelstadt, Chris Russell, and Sandra Wachter. 2019. Explaining Explanations in AI (FAT* ’19) . Association for Computing Machinery, New York, NY, USA, 279–288. https://doi.org/10.1145/3287560.3287574 [104] JefferyJ.Mondak.1992. InstitutionalLegitimacy,PolicyLegitimacy,andtheSupremeCourt. AmericanPoliticsQuarterly 20, 4 (1992), 457–477. https://doi.org/10.1177/1532673X9202000406 arXiv:https://doi.org/10.1177/1532673X9202000406 [105] Shinichi Nakagawa and Holger Schielzeth. 2013. A general and simple method for obtaining R2 from generalized",0.09429629629629624,0.12040394472222225,0.9084655220864197,0.8786721391666666,,
246,180,26,Footer,"[(608, 623), (623, 637)]","linear mixed-effects models. Methods in Ecology and Evolution 4, 2 (2013), 133–142. https://doi.org/10.1111/j.2041- 210x.2012.00261.x arXiv:https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/j.2041-210x.2012.00261.x Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.13704938271604938,0.8814386669444444,0.9074507863150205,0.9450888058333333,,
247,181,27,Header,"[(0, 1)]",82:28,0.09429629629629631,0.08305529208333332,0.12840701234567903,0.09412487541666666,,
248,182,27,Bibliography,"[(1, 6), (6, 25), (25, 37), (37, 56), (56, 90), (90, 113), (113, 131), (131, 137), (137, 153), (153, 174), (174, 203), (203, 245), (245, 256), (256, 276), (276, 286), (286, 310), (310, 327), (327, 356), (356, 370), (370, 374), (374, 392), (392, 418), (418, 440), (440, 473), (473, 498), (498, 517), (517, 527), (527, 560), (560, 581), (581, 592)]","Pan, Yakhmi, Iyer, et. al. [106] Jeff Neal and HLS News Staff. 2021. Did Facebook’s Oversight Board get the Trump decision right? https://today.law. harvard.edu/did-facebooks-oversight-board-get-the-trump-decision-right/ [107] Casey Newton. 2019. The Trauma Floor. The Verge (2019). https://www.theverge.com/2019/2/25/18229714/cognizant- facebook-content-moderator-interviews-trauma-working-conditions-arizona [108] Jakob Nielsen. 2006. The 90-9-1 Rule for Participation Inequality in Social Media and Online Communities . https: //www.nngroup.com/articles/participation-inequality/ [109] Ziad Obermeyer and Sendhil Mullainathan. 2019. Dissecting Racial Bias in an Algorithm That Guides Health Decisions for 70 Million People. In Proceedings of the Conference on Fairness, Accountability, and Transparency (Atlanta, GA, USA) (FAT* ’19) . Association for Computing Machinery, New York, NY, USA, 89. https://doi.org/10.1145/3287560.3287593 [110] U.S. Department of Labor. [n.d.]. Minimum Wage. ([n.d.]). https://www.dol.gov/general/topic/wages/minimumwage [111] Andrew Perrin and Monica Anderson. 2019. Share of U.S. adults using social media, including Facebook, is mostly unchanged since 2018 . https://www.pewresearch.org/fact-tank/2019/04/10/share-of-u-s-adults-using-social-media- including-facebook-is-mostly-unchanged-since-2018/ [112] Fabienne Peter. 2009. Democratic legitimacy . Routledge. [113] Fabienne Peter. 2017. Political Legitimacy . https://plato.stanford.edu/entries/legitimacy [114] Kevin Randall. 2021. Social app Parler is cracking down on hate speech — but only on iPhones . https://www. washingtonpost.com/technology/2021/05/17/parler-apple-app-store/ [115] Dennis Redeker, Lex Gill, and Urs Gasser. 2018. Towards digital constitutionalism? Mapping attempts to craft an Internet Bill of Rights. International Communication Gazette 80 (02 2018), 174804851875712. https://doi.org/10.1177/ 1748048518757121 [116] Sarah T Roberts. 2019. Behind the screen: Content moderation in the shadows of social media . Yale University Press. [117] Michel Rosenfeld. 2000. The rule of law and the legitimacy of constitutional democracy. S. Cal. L. Rev. 74 (2000), 1307. [118] John Samples. 2020. Independence in Content Moderation . https://www.cato.org/blog/independence-content- moderation [119] Sarita Schoenebeck, Oliver L Haimson, and Lisa Nakamura. 2018. Drawing from justice theories to support targets of online harassment. New Media & Society 80, 4 (2018), 295–301. https://doi.org/10.1177/1461444820913122 arXiv:https://doi.org/10.1177/1461444820913122 [120] Melissa Schwartzberg. [n.d.]. Civil Juries and Democratic Legitimacy. ([n.d.]). [121] Joseph Seering. 2020. Reconsidering Self-Moderation: The Role of Research in Supporting Community-Based Models for Online Content Moderation. Proc. ACM Hum.-Comput. Interact. 4, CSCW2, Article 107 (Oct. 2020), 28 pages. https://doi.org/10.1145/3415178 [122] Isabella Garcia-Camargo Julia Greenberg Tara Iyer Alejandra Lynberg Madeline Magnuson Shawn Musgrave Ashwin Ramaswami Nora Tan Marlena Wisniak Monica Zwolinski Paul Brest Daniel Ho Nathaniel Persily Rob Reich Liza Starr Shaimaa Bakr, Fernando Berdion-Del Valle. 2019. Recommendation for the Facebook Content Review Board . https://www-cdn.law.stanford.edu/wp-content/uploads/2019/07/Stanford_Policy_Lab_Recs_for_Facebook_ Content_Review_Board__FINAL.pdf [123] Donna Shestowsky. 2004. Procedural Preferences in Alternative Dispute Resolution: A Closer, Modern Look at an Old Idea. Psychology, Public Policy, & Law. 10 (10 2004). https://doi.org/10.1037/1076-8971.10.3.211 [124] Rashmi R Sinha, Kirsten Swearingen, et al. 2001. Comparing recommendations made by online systems and friends. DELOS 106 (2001). [125] Linda J Skitka, Christopher W Bauman, and Brad L Lytle. 2009. Limits on legitimacy: moral and religious convictions as constraints on deference to authority. Journal of personality and social psychology 97, 4 (2009), 567. [126] Jason M Solomon. 2011. The Political Puzzle of the Civil Jury. Emory LJ 61 (2011), 1331. [127] S Shyam Sundar. 2008. The MAIN model: A heuristic approach to understanding technology effects on credibility . MacArthur Foundation Digital Media and Learning Initiative. [128] Nicolas Suzor. 2018. Digital Constitutionalism: Using the Rule of Law to Evaluate the Legitimacy of Governance by Platforms. Social Media + Society 4, 3 (2018), 2056305118787812. https://doi.org/10.1177/2056305118787812 arXiv:https://doi.org/10.1177/2056305118787812 [129] Nicolas Suzor, Tess Van Geelen, and Sarah Myers West. 2018. Evaluating the legitimacy of platform governance: A review of research and a shared research agenda. International Communication Gazette 80, 4 (2018), 385–400. https://doi.org/10.1177/1748048518757142 arXiv:https://doi.org/10.1177/1748048518757142 [130] Nicolas Suzor, Sarah West, Andrew Quodling, and Jillian York. 2019. What Do We Mean When We Talk About Transparency? Toward Meaningful Transparency in Commercial Content Moderation. International Journal of",0.09429629629629624,0.08305529208333332,0.9082305283497942,0.8535652825,,
249,183,27,Footnote,"[(592, 615), (615, 632)]","Communication 13, 0 (2019). https://ijoc.org/index.php/ijoc/article/view/9736 [131] Nicolas P Suzor. 2019. Lawless: The secret rules that govern our digital lives . Cambridge University Press. [132] Kara Swisher. 2021. If You Were on Parler, You Saw the Mob Coming . https://www.nytimes.com/2021/01/07/opinion/ sway-kara-swisher-john-matze.html?showTranscript=1",0.09429629629629624,0.8537650558333334,0.9067652303893005,0.9063457502777779,,
250,184,27,Footer,"[(632, 646)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.09429629629629628,0.9340192225,0.7380540648148148,0.9450888058333333,,
251,185,28,Header,"[(0, 8), (8, 9)]",Comparing The Perceived Legitimacy of Content Moderation Processes 82:29,0.09429629629629631,0.08305529208333332,0.9057049543209879,0.09412487541666666,,
252,186,28,Bibliography,"[(9, 28), (28, 62), (62, 88), (88, 118), (118, 139), (139, 164), (164, 184), (184, 199), (199, 226), (226, 251), (251, 275), (275, 303), (303, 335), (335, 364), (364, 384), (384, 402), (402, 420), (420, 445), (445, 467)]","[133] Taster. 2019. The political dilemma of expertise – More than just public trust in experts . https://blogs.lse.ac.uk/ impactofsocialsciences/2019/06/17/the-political-dilemma-of-expertise-more-than-just-public-trust-in-experts/ [134] Stephen Turner. 2001. What is the Problem with Experts? Social studies of science 31, 1 (2001), 123–149. [135] Heidi Tworek, Ronan Ó Fathaigh, Lisanne Bruggeman, and Chris Tenove. 2020. Dispute Resolution and Content Moderation: Fair, Accountable, Independent. Algorithms (2020). [136] Tom R Tyler. 2003. Procedural justice, legitimacy, and the effective rule of law. Crime and justice 30 (2003), 283–357. [137] Tom R Tyler. 2007. Legitimacy and criminal justice: An International perspective . Russell Sage Foundation. [138] Tom R. Tyler. 2016. Why Procedural Justice Matters: Tom R. Tyler . https://www.youtube.com/watch?v=H86jZs5plIw [139] Tom R. Tyler and Yuen J. Huo. 2002. Trust in the Law: Encouraging Public Cooperation with the Police and Courts Through . Russell Sage Foundation. http://www.jstor.org/stable/10.7758/9781610445429 [140] Kristen Vaccaro, Christian Sandvig, and Karrie Karahalios. 2020. ""At the End of the Day Facebook Does What ItWants"": How Users Experience Contesting Algorithmic Content Moderation. Proc. ACM Hum.-Comput. Interact. 4, CSCW2, Article 167 (Oct. 2020), 22 pages. https://doi.org/10.1145/3415238 [141] Kristen Vaccaro, Ziang Xiao, Kevin Hamilton, and Karrie Karahalios. 2021. Contestability For Content Moderation. Proceedings of the ACM on Human-Computer Interaction 5, CSCW2 (2021), 1–28. [142] Andreas Veglis. 2014. Moderation techniques for social media content. In International Conference on Social Computing and Social Media . Springer, 137–148. [143] Philip D Waggoner, Ryan Kennedy, Hayden Le, and Myriam Shiran. 2019. Big Data and Trust in Public Policy Automation. Statistics, Politics and Policy 10, 2 (2019), 115–136. [144] Ruotong Wang, Franklin Harper, and Haiyi Zhu. 2020. Factors Influencing Perceived Fairness in Algorithmic Decision-Making: Algorithm Outcomes, Development Procedures, and Individual Differences. [145] Max Weber. 1964. The Theory of Social and Economic Organization: Transl. by AM Henderson and Talcott Parsons . Free Press. [146] Max Weber. 2009. The theory of social and economic organization . Simon and Schuster. [147] Maranke Wieringa. 2020. What to Account for When Accounting for Algorithms: A Systematic Literature Review on Algorithmic Accountability. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (Barcelona, Spain) (FAT* ’20) . Association for Computing Machinery, New York, NY, USA, 1–18. https://doi.org/10. 1145/3351095.3372833 [148] Georgios N. Yannakakis and Héctor P. Martínez. 2015. Ratings are Overrated! Frontiers in ICT 2 (2015), 13. https: //doi.org/10.3389/fict.2015.00013 [149] Amy X. Zhang, Grant Hugh, and Michael S. Bernstein. 2020. PolicyKit: Building Governance in Online Communities. In Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology (Virtual Event, USA) (UIST ’20) . Association for Computing Machinery, New York, NY, USA, 365–378. https://doi.org/10.1145/3379337.3415858 [150] Mark Zuckerberg. 2018. A Blueprint for Content Governance and Enforcement . https://www.facebook.com/notes/mark- zuckerberg/a-blueprint-for-content-governance-and-enforcement/10156443129621634/?hc_location=ufi [151] E. Zuckerman. 2021. Mistrust: Why Losing Faith in Institutions Provides the Tools to Transform Them . W. W. Norton. https://books.google.com/books?id=ZTTTDwAAQBAJ",0.09429629629629624,0.12040394472222225,0.908235796125926,0.6296054725,,
253,187,28,Footer,"[(467, 481)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.26194238683127574,0.9340192225,0.9057001553497942,0.9450888058333333,,
254,188,29,Header,"[(0, 1), (1, 6)]","82:30 Pan, Yakhmi, Iyer, et. al.",0.09429629629629631,0.08305529208333332,0.9057092407407409,0.09412487541666666,,
255,189,29,Section,"(6, 11)",7 APPENDICES 7.1 Appendix A,0.09429629629629636,0.1208522894444444,0.25185297037037047,0.15544478944444443,,
256,189,29,Section,"(11, 14)",Content Moderation Process,0.10454526748971193,0.18221062277777772,0.3290317543209877,0.19604756722222227,,
257,190,29,Table,"[(14, 15)]",Description,0.3500229115226338,0.18221062277777772,0.4418592242798356,0.19604756722222227,,
258,191,29,Section,"(15, 17)",Paid Contractor,0.10454526748971193,0.20255184055555556,0.23742093251028804,0.21638878499999994,,
259,192,29,Paragraph,"[(17, 27), (27, 37), (37, 46)]",The content moderation decision was made by a human contractor employed by Facebook. The human contractor was trained in a workshop with examples of posts that violated Facebook’s Commu-,0.3492551440329218,0.20255184055555556,0.9075660127613167,0.2495971183333334,,
260,193,29,List,"[(46, 48)]",nity Standards.,0.3500144032921811,0.25236572944444446,0.4758178522633744,0.2662026738888888,,
261,194,29,Table,"[(48, 49)]",Algorithm,0.10454526748971193,0.26896989611111116,0.1916667695473251,0.28280684055555555,,
262,195,29,List,"[(49, 59), (59, 69), (69, 78), (78, 79)]",The content moderation decision was made by an algorithm that was built by software engineers at Facebook. The algorithm was trained on examples of posts that violated Facebook’s Community Standards.,0.3492551440329218,0.26896989611111116,0.9046402169761315,0.33261934055555553,,
263,196,29,Section,"(79, 81)",Digital Jury,0.10454526748971193,0.33538656277777773,0.202633829218107,0.3492235072222222,,
264,197,29,Paragraph,"[(81, 93), (93, 102), (102, 110), (110, 120)]","The content moderation decision was made by a jury of 6 randomly- selected Facebook users. Jury members received training on enforc- ing Facebook’s Community Standards, and after structured deliber- ation in a video conference session, reached a unanimous decision.",0.3493991769547325,0.33538656277777773,0.9075813158905346,0.39903739611111105,,
265,198,29,Section,"(120, 122)",Expert Panel,0.10454526748971193,0.4018046183333333,0.21132548024691356,0.4156415627777778,,
266,199,29,Paragraph,"[(122, 134), (134, 143), (143, 152), (152, 158)]","The content moderation decision was made by a panel of 6 experts selected for their expertise in content moderation, human rights, and digital rights. After structured deliberation in a videoconference session, they reached a unanimous decision.",0.3493991769547325,0.4018046183333333,0.9063653457119342,0.46545545166666663,,
267,200,29,Caption,"[(158, 173), (173, 174)]",Table 7. Descriptions of each of the moderation processes shown to survey participants with decision outcomes.,0.09379835390946502,0.4735201377777778,0.9056981251687242,0.5011943044444445,Table,0.0
268,201,29,Footer,"[(174, 188)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.09429629629629631,0.9340192225,0.7380540648148148,0.9450888058333333,,
269,202,30,Header,"[(0, 8), (8, 9)]",Comparing The Perceived Legitimacy of Content Moderation Processes 82:31,0.09429629629629631,0.08305529208333332,0.9057049543209879,0.09412487541666666,,
270,203,30,Section,"(9, 12)",7.2 Appendix B,0.09429629629629631,0.1208522894444444,0.2505410230452675,0.13468923388888893,,
271,204,30,Paragraph,"[(12, 13), (13, 14)]",Predicate Description,0.11748559670781893,0.16085160888888891,0.23770177448559665,0.1691538311111112,,
272,204,30,Paragraph,"[(14, 15), (15, 17), (17, 19), (19, 21), (21, 23), (23, 25), (25, 27), (27, 29), (29, 31), (31, 33), (33, 35), (35, 37), (37, 39), (39, 41), (41, 43), (43, 45), (45, 47), (47, 49), (49, 51), (51, 53), (53, 55), (55, 57), (57, 59), (59, 61), (61, 63), (63, 65), (65, 67), (67, 69), (69, 71), (71, 73), (73, 75), (75, 77), (77, 79), (79, 81), (81, 83), (83, 85), (85, 87), (87, 89), (89, 91), (91, 93), (93, 95), (95, 97), (97, 99), (99, 101), (101, 103), (103, 105), (105, 107), (107, 109), (109, 110)]","1 Subjecttosinglepersonbias 2 Abusespower 3 Doesn’tabusepower 4 Appliesownbeliefsandagenda 5 Doesn’tapplyownbeliefsandagenda 6 Allowsformultipleperspectivestomitigatebias 7 Suffersfromgroup-thinkorpeerpressure 8 Hasnecessaryformaltrainingandexperience 9 Lacksnecessaryformaltrainingandexperience 10 Takesworkseriouslybecauseit’stheirjob 11 Doesn’ttakeseriouslybecausenotcompensated(enough) 12 Doesn’ttakeseriouslybecauseit’sjustajob 13 Subjecttocontrolbytheplatform 14 Independentfromtheplatform 15 Subjectto(improper)influencebythirdparties 16 Notsubjectto(improper)influencebythirdparties 17 Hasrigorousandfairselectionprocess 18 Lacksrigorousandfairselectionprocess 19 Selectioncontrolledbytheplatform 20 Accountablefordecisions 21 Unaccountable(e.g.,lacksoversight) 22 Makesconsistentdecisions 23 Makesinconsistentdecisions 24 Faithfullyadherestomoderationguidelines 25 Doesn’tfaithfullyadheretomoderationguidelines 26 Makesagood-faithattempttoconsiderallfactorsandsides 27 Idon’tunderstandprocesswellenough 28 Performedwellinthesurveyexamples 29 Performedpoorlyinthesurveyexamples 30 Generallyperformswell 31 Generallyperformspoorly 32 Makesdecisionsbasedonlogic,data,and/orrules,notfeelings 33 Mayhaverelationshipwithdefendant 34 Norelationshiptodefendant 35 Hashumanfactorsofcognition 36 Lackshumanfactorsofcognition 37 Canbeprogrammedwithbiases 38 Canbetrainedorprogrammedpoorly 39 Canbeoptimizedorimprovedovertime 40 Costlyorimpractical 41 Composedofregularusers(whoarewellequippedtomakedecisions) 42 Composedofregularusers(whoareunsuitedtomakedecisions) 43 Idonottrust 44 Resemblescriminaljusticesystem 45 Itrust 46 Considersbroadersocialcontext 47 Doesnotconsiderbroadersocialcontext 48 Concernedwithupholdingindividualrights",0.11748559670781893,0.1755588266666668,0.5343063506172839,0.6390985488888892,,
273,205,30,Caption,"[(110, 126), (126, 143), (143, 151)]","Table 8. Predicates used for qualitative coding of the free responses written by survey participants. Each predicate represents a core idea expressed in the participant’s response, and can be used to represent a rationale or a qualification for the opinion expressed.",0.09379835390946502,0.6450993044444445,0.9057067899259256,0.6879943044444444,Table,0.0
274,206,30,Footer,"[(151, 165)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.26194238683127574,0.9340192225,0.9057001553497942,0.9450888058333333,,
275,207,31,Header,"[(0, 1), (1, 6)]","82:32 Pan, Yakhmi, Iyer, et. al.",0.09429629629629631,0.08305529208333332,0.9057092407407409,0.09412487541666666,,
276,208,31,Section,"(6, 9)",7.3 Appendix C,0.09429629629629636,0.1208522894444444,0.2511764975308643,0.13468923388888893,,
277,209,31,Table,"[(9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (15, 16), (16, 17), (17, 18), (18, 19), (19, 20), (20, 22), (22, 23), (23, 24), (24, 25), (25, 27), (27, 28), (28, 29), (29, 30), (30, 31), (31, 33), (33, 34), (34, 35), (35, 36), (36, 39), (39, 40), (40, 41), (41, 42), (42, 43), (43, 45), (45, 46), (46, 47), (47, 48), (48, 51), (51, 52), (52, 53), (53, 54), (54, 55), (55, 57), (57, 58), (58, 59), (59, 60), (60, 62), (62, 63), (63, 64), (64, 65), (65, 66), (66, 68), (68, 69), (69, 70), (70, 71), (71, 73), (73, 74), (74, 75), (75, 76), (76, 77), (77, 79), (79, 80), (80, 81), (81, 82), (82, 84), (84, 85), (85, 86), (86, 87), (87, 88), (88, 90), (90, 91), (91, 92), (92, 93), (93, 96), (96, 97), (97, 98), (98, 99), (99, 100), (100, 102), (102, 103), (103, 104), (104, 105), (105, 109), (109, 110), (110, 111), (111, 112), (112, 113), (113, 115), (115, 116), (116, 117), (117, 118), (118, 123), (123, 124), (124, 125), (125, 126), (126, 127), (127, 129), (129, 130), (130, 131), (131, 132), (132, 137), (137, 138), (138, 139), (139, 140), (140, 141), (141, 143), (143, 144), (144, 145), (145, 146), (146, 148), (148, 149), (149, 150), (150, 151), (151, 152), (152, 154), (154, 155), (155, 156), (156, 157), (157, 158)]",Variable Satisfaction Impartiality Trustworthiness Commitment Jurisdiction Alignment 0.66*** 0.29*** 0.27*** 0.34*** 0.33*** (0.12) (0.03) (0.03) (0.04) (0.04) Algorithm -0.01 -0.18* -0.07 -0.14 -0.11 (0.03) (0.08) (0.08) (0.09) (0.09) Expert Panel 0.07 0.22** 0.21** 0.25** 0.36*** (0.08) (0.08) (0.08) (0.09) (0.09) Digital Jury -0.03 -0.04 -0.18* -0.18 -0.27** (0.08) (0.08) (0.08) (0.09) (0.09) Male -0.03 -0.09 -0.06 -0.14 -0.09 (0.13) (0.15) (0.16) (0.15) (0.17) Conservative -0.22 -0.24 -0.32 -0.33 -0.02 (0.17) (0.19) (0.21) (0.18) (0.21) Independent -0.37* -0.38* -0.67** -0.46* -0.34 (0.18) (0.18) (0.20) (0.19) (0.20) Unreported Affiliation -1.13* -0.38 -0.90 -0.92 -0.38 (0.45) (0.52) (0.56) (0.52) (0.63) Alignment * Algorithm -0.05 0.09 0.02 0.06 0.04 (0.06) (0.06) (0.06) (0.06) (0.06) Alignment * Expert Panel 0.07 -0.03 0.04 0.01 0.07 (0.06) (0.06) (0.06) (0.07) (0.06) Alignment * Digital Jury 0.01 0.03 0.02 0.04 -0.02 (0.06) (0.06) (0.06) (0.07) (0.07) Constant 3.59*** 3.61*** 3.65*** 3.61*** 3.25*** (0.12) (0.14) (0.15) (0.14) (0.16),0.09429629629629627,0.16163736583333335,0.8954061419753089,0.5091749169444444,,
278,210,31,Caption,"[(158, 170), (170, 181), (181, 195), (195, 208), (208, 223), (223, 239), (239, 262)]","Table 9. Regression coefficients of perceived institutional legitimacy submodels, whose dependent variables are outcome satisfaction, fairness and impartiality, trustworthiness, institutional commitment, and decisional jurisdiction, respectively. Process is modeled using deviation contrasts such that the Constant reflects the mean across processes, and coefficients are comparable between models. Significance levels are indicated for readability purposes only and are calculated with t-tests using Satterthwaite’s method [97]. These levels are not calculated with the Bonferroni correction used for hypothesis tests, and do not constitute formal hypothesis tests. | 𝑝 < 0 . 001 *** , 𝑝 < 0 . 01 ** , 𝑝 < 0 . 05 *",0.09379835390946502,0.5164159711111111,0.9057082658765431,0.6210939311111111,Table,0.0
279,211,31,Paragraph,"[(262, 271)]",Received January 2021; revised July 2021; accepted November 2021,0.09429629629629618,0.6423437955555555,0.5970788740740742,0.654797128888889,,
280,212,31,Footer,"[(271, 285)]","Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW1, Article 82. Publication date: April 2022.",0.09429629629629618,0.9340192225,0.7380540648148148,0.9450888058333333,,
